{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning Project\n",
    "This notebook demonstrates how to set up and compare Federated Learning (FL) with Centralized Learning (CL) using the CIFAR-100 dataset and the modified version of the LeNet-5 model taken from [Hsu et al., Federated Visual Classification with Real-World Data Distribution, ECCV 2020]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "We start by importing necessary libraries and setting global constants for the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from models.model import LeNet5 #import the model\n",
    "\n",
    "sys.path.append('../data/cifar100/')\n",
    "from cifar100_loader import load_cifar100\n",
    "\n",
    "from utils.federated_utils import fedAvg,plot_client_selection,test,plot_metrics,save_model,load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "NUM_CLIENTS = 100  # Total number of clients in the federation\n",
    "FRACTION_CLIENTS = 0.1  # Fraction of clients selected per round (C)\n",
    "LOCAL_EPOCHS = 4  # Number of local steps (J)\n",
    "GLOBAL_ROUNDS = 2000  # Total number of communication rounds\n",
    "\n",
    "BATCH_SIZE = 32  # Batch size for local training\n",
    "LR = 0.01  # Initial learning rate for local optimizers: best one from the centralized one\n",
    "MOMENTUM = 0.9  # Momentum for SGD optimizer\n",
    "WEIGHT_DECAY = 0.0001  # Regularization term for local training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "We load the CIFAR-100 dataset and split it into training, validation, and test sets. This is done using the `data_loader.py` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#load the dataset\n",
    "trainloader, validloader, testloader = load_cifar100(batch_size=BATCH_SIZE, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Federated Training\n",
    "We simulate federated learning by splitting the dataset into shards and training with selected clients in each round."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Model & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = LeNet5()\n",
    "criterion = nn.NLLLoss()# our loss function for classification tasks on CIFAR-100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning for the first federated training baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.05, Weight decay: 0.001\n"
     ]
    }
   ],
   "source": [
    "lr = [0.05, 0.01, 0.005, 0.0001]\n",
    "wd = [0.001, 0.0005, 0.0001]\n",
    "rounds = 200 #fewer communication rounds for hyperparameter tuning\n",
    "results = []\n",
    "best_val_accuracy = 0\n",
    "best_setting = None\n",
    "for l in lr:\n",
    "    for w in wd:\n",
    "        print(f\"Learning rate: {l}, Weight decay: {w}\")\n",
    "        global_model = LeNet5()\n",
    "        #global_model,dataset, valid_dataset, num_clients,num_classes, rounds,lr,wd, C=0.1, local_steps=4,gamma=None\n",
    "        val_accuracies,val_losses,train_accuracies,train_losses,global_model,client_selection_count = fedAvg(global_model, trainloader, validloader, NUM_CLIENTS, 100, rounds, l, w)\n",
    "        print(f\"Validation accuracy: {val_accuracies[-1]} with lr: {l} and wd: {w}\")\n",
    "        if val_accuracies[-1] > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracies[-1]\n",
    "            best_setting = (l,w)\n",
    "        results.append({\n",
    "                'learning_rate': l,\n",
    "                'weight_decay': w,\n",
    "                'train_accuracies': train_accuracies,\n",
    "                'train_losses': train_losses,\n",
    "                'val_accuracies': val_accuracies,\n",
    "                'val_losses': val_losses,\n",
    "                'client_selection_count': client_selection_count\n",
    "        })\n",
    "print(f\"Best setting: {best_setting} with validation accuracy: {best_val_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2000 rounds using lr and wd found in the step before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr =\n",
    "#wd = \n",
    "NUM_ROUNDS = 2000\n",
    "global_model = LeNet5()\n",
    "val_accuracies,val_losses,train_accuracies,train_losses,global_model,client_selection_count = fedAvg(global_model, trainloader, validloader, NUM_CLIENTS, 100, NUM_ROUNDS, lr, wd)\n",
    "plot_client_selection(client_selection_count, \"clientDistribution_iid\")\n",
    "test_accuracy = test(global_model, testloader)\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n",
    "#Plot also training accuracy against validation accuracy and validation loss against training loss\n",
    "plot_metrics(train_accuracies, val_accuracies, train_losses, val_losses, \"iid\")\n",
    "#Save the model for the future\n",
    "save_model(global_model, \"iid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
