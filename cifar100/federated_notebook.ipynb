{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning Project\n",
    "This notebook demonstrates how to set up and compare Federated Learning (FL) with Centralized Learning (CL) using the CIFAR-100 dataset and the LeNet-5 model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "We start by importing necessary libraries and setting global constants for the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LeNet5 \u001b[38;5;66;03m#import the model\u001b[39;00m\n\u001b[0;32m     12\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/cifar100/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcifar100_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_cifar100\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Constants for FL training\u001b[39;00m\n\u001b[0;32m     16\u001b[0m DEVICE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Luca\\Desktop\\POLITO\\AdvancedMachineLearning\\Project_Federated_Learning\\AML_FederatedLearning\\cifar100\\../data/cifar100\\cifar100_loader.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, Subset\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_cifar100\u001b[39m(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m      7\u001b[0m     transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m      8\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m      9\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.5071\u001b[39m, \u001b[38;5;241m0.4867\u001b[39m, \u001b[38;5;241m0.4408\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.2675\u001b[39m, \u001b[38;5;241m0.2565\u001b[39m, \u001b[38;5;241m0.2761\u001b[39m])\n\u001b[0;32m     10\u001b[0m     ])\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from torch.utils.data import Subset\n",
    "from statistics import mean\n",
    "\n",
    "from models.model import LeNet5 #import the model\n",
    "\n",
    "sys.path.append('../data/cifar100/')\n",
    "from cifar100_loader import load_cifar100\n",
    "\n",
    "from federated_utils import shard_dataset_iid, client_update, fedavg_aggregate\n",
    "\n",
    "\n",
    "# Constants for FL training\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "NUM_CLIENTS = 100  # Total number of clients in the federation\n",
    "FRACTION_CLIENTS = 0.1  # Fraction of clients selected per round (C)\n",
    "LOCAL_EPOCHS = 4  # Number of local steps (J)\n",
    "GLOBAL_ROUNDS = 200  # Total number of communication rounds\n",
    "\n",
    "BATCH_SIZE = 64  # Batch size for local training\n",
    "LR = 1e-3  # Initial learning rate for local optimizers\n",
    "MOMENTUM = 0.9  # Momentum for SGD optimizer\n",
    "WEIGHT_DECAY = 5e-5  # Regularization term for local training\n",
    "\n",
    "LOG_FREQUENCY = 10  # Frequency of logging training progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "We load the CIFAR-100 dataset and split it into training, validation, and test sets. This is done using the `data_loader.py` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "trainloader, validloader, testloader = load_cifar100(batch_size=BATCH_SIZE, validation_split=0.25)\n",
    "\n",
    "print(\"Data loaded successfully!\\n\")\n",
    "print(\"Dimension of the training dataset:\", len(trainloader.dataset))\n",
    "print(\"Dimension of the validation dataset:\", len(validloader.dataset))\n",
    "print(\"Dimension of the test dataset:\", len(testloader.dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
