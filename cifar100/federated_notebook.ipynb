{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning Project\n",
    "This notebook demonstrates how to set up and compare Federated Learning (FL) with Centralized Learning (CL) using the CIFAR-100 dataset and the LeNet-5 model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "We start by importing necessary libraries and setting global constants for the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'fedAvg' from 'utils.federated_utils' (c:\\Users\\Stefano\\OneDrive\\Desktop\\AML_FederatedLearning\\cifar100\\utils\\federated_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/cifar100/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcifar100_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_cifar100\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfederated_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fedAvg,plot_client_selection\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'fedAvg' from 'utils.federated_utils' (c:\\Users\\Stefano\\OneDrive\\Desktop\\AML_FederatedLearning\\cifar100\\utils\\federated_utils.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models.model import LeNet5 #import the model\n",
    "\n",
    "sys.path.append('../data/cifar100/')\n",
    "from cifar100_loader import load_cifar100\n",
    "\n",
    "from utils.federated_utils import fedAvg,plot_client_selection\n",
    "from utils.utils import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "NUM_CLIENTS = 100  # Total number of clients in the federation\n",
    "FRACTION_CLIENTS = 0.1  # Fraction of clients selected per round (C)\n",
    "LOCAL_EPOCHS = 4  # Number of local steps (J)\n",
    "GLOBAL_ROUNDS = 2000  # Total number of communication rounds\n",
    "\n",
    "BATCH_SIZE = 32  # Batch size for local training\n",
    "LR = 0.01  # Initial learning rate for local optimizers: best one from the centralized one\n",
    "MOMENTUM = 0.9  # Momentum for SGD optimizer\n",
    "WEIGHT_DECAY = 0.0001  # Regularization term for local training\n",
    "\n",
    "LOG_FREQUENCY = 10  # Frequency of logging training progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "We load the CIFAR-100 dataset and split it into training, validation, and test sets. This is done using the `data_loader.py` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "trainloader, validloader, testloader = load_cifar100(batch_size=BATCH_SIZE, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Federated Training\n",
    "We simulate federated learning by splitting the dataset into shards and training with selected clients in each round."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Model & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = LeNet5()\n",
    "criterion = nn.NLLLoss()# our loss function for classification tasks on CIFAR-100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning for the first federated training baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = [0.05, 0.01, 0.005, 0.0001]\n",
    "wd = [0.001, 0.0005, 0.0001]\n",
    "rounds = 200 #fewer round for hyperparameter tuning\n",
    "results = []\n",
    "for l in lr:\n",
    "    for w in wd:\n",
    "        print(f\"Learning rate: {l}, Weight decay: {w}\")\n",
    "        global_model = LeNet5()\n",
    "        #global_model,dataset, valid_dataset, num_clients,num_classes, rounds,lr,wd, C=0.1, local_steps=4,gamma=None\n",
    "        val_accuracies,val_losses,train_accuracies,train_losses,global_model,client_selection_count = fedAvg(global_model, trainloader, validloader, NUM_CLIENTS, 100, rounds, lr, wd)\n",
    "        print(f\"Validation accuracy: {val_accuracies[-1]} with lr: {l} and wd: {w}\")\n",
    "        results.append({\n",
    "                'learning_rate': l,\n",
    "                'weight_decay': w,\n",
    "                'train_accuracies': train_accuracies,\n",
    "                'train_losses': train_losses,\n",
    "                'val_accuracies': val_accuracies,\n",
    "                'val_losses': val_losses,\n",
    "                'client_selection_count': client_selection_count\n",
    "        })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
