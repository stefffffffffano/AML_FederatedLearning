{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6AYtngaiB0cJ"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from Server import Server\n",
        "from Client import Client\n",
        "from Individual import Individual\n",
        "from shakespeare_model import CharLSTM\n",
        "from statistics import mean\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjnl6b5eDPMY",
        "outputId": "c4d10b74-5e53-4753-fcdb-3b2d12da965d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# Constants for FL training\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(DEVICE)\n",
        "FRACTION_CLIENTS = 0.1  # Fraction of clients selected per round (C)\n",
        "BATCH_SIZE = 100 # Batch size for local training\n",
        "MOMENTUM = 0  # Momentum for SGD optimizer\n",
        "LOG_FREQUENCY = 10 # Frequency of logging training progress"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uqI29GCvE8F_"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Utility function used both in the centralized and federated learning\n",
        "Computes the accuracy and the loss on the validation/test set depending on the dataloader passed\n",
        "\"\"\"\n",
        "def evaluate(model, dataloader, criterion, DEVICE):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    running_corrects = 0\n",
        "    total_samples = 0  # Total samples counter\n",
        "    losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, targets in dataloader:\n",
        "            data = data.to(DEVICE)\n",
        "            targets = targets.to(DEVICE)\n",
        "            hidden = model.init_hidden(data.size(0))\n",
        "            hidden = (hidden[0].to(DEVICE), hidden[1].to(DEVICE))\n",
        "            outputs, _ = model(data, hidden)\n",
        "            outputs_flat = outputs.view(-1, model.vocab_size)\n",
        "            targets_flat = targets.view(-1)\n",
        "\n",
        "            loss = criterion(outputs_flat, targets_flat)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            _, preds = outputs_flat.max(1)\n",
        "            #running_corrects += torch.sum(preds == targets_flat).item()\n",
        "            running_corrects += (preds == targets_flat).sum().item()\n",
        "            total_samples += targets_flat.size(0)\n",
        "\n",
        "    accuracy = (running_corrects / total_samples) * 100\n",
        "    return accuracy, sum(losses) / len(losses)\n",
        "\n",
        "\n",
        "def test(global_model, test_loader, criterion, DEVICE):\n",
        "    \"\"\"\n",
        "    Evaluate the global model on the test dataset.\n",
        "\n",
        "    Args:\n",
        "        global_model (nn.Module): The global model to be evaluated.\n",
        "        test_loader (DataLoader): DataLoader for the test dataset.\n",
        "\n",
        "    Returns:\n",
        "        float: The accuracy of the model on the test dataset.\n",
        "        float: The loss of the model on the test dataset.\n",
        "    \"\"\"\n",
        "    test_accuracy, loss = evaluate(global_model, test_loader, criterion, DEVICE)\n",
        "    return test_accuracy, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVSI_pV5lfmR"
      },
      "source": [
        "# DataLoading Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first need to import the file that contains the dataset we want to load for training and for testing porpouse.\n",
        "\n",
        "If you are using colab we suggest you to change the following code block with:\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded2 = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Please upload the training dataset provided by LEAF here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "root = tk.Tk()\n",
        "#root.withdraw()\n",
        "\n",
        "file_path = filedialog.askopenfilename(filetypes=[(\"JSON files\", \"*.json\")])\n",
        "\n",
        "if file_path:\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "            \n",
        "root.destroy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Please upload the test dataset provided by LEAF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "root = tk.Tk()\n",
        "#root.withdraw()\n",
        "\n",
        "file_path = filedialog.askopenfilename(filetypes=[(\"JSON files\", \"*.json\")])\n",
        "\n",
        "if file_path:\n",
        "    with open(file_path, 'r') as file:\n",
        "        test_data = json.load(file)\n",
        "            \n",
        "root.destroy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbR2pJ1WeuLM",
        "outputId": "a07ebacc-8861-4bae-d640-2ee723afafc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of clients: 100\n"
          ]
        }
      ],
      "source": [
        "num_clients = len(data['users'])\n",
        "print(\"Number of clients:\", num_clients)\n",
        "NUM_CLIENTS = num_clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "i9UliC2qnQUe"
      },
      "outputs": [],
      "source": [
        "users = data['users']\n",
        "num_samples = data['num_samples']\n",
        "user_data = data['user_data']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Y1an7TUynSM3"
      },
      "outputs": [],
      "source": [
        "all_texts = ''.join([''.join(seq) for user in users for seq in user_data[user]['x']])\n",
        "chars = sorted(set(all_texts))\n",
        "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
        "\n",
        "# Add the padding character\n",
        "char_to_idx['<pad>'] = len(char_to_idx)\n",
        "idx_to_char = {idx: ch for ch, idx in char_to_idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDItE3pL82K7"
      },
      "source": [
        "## Convert data into indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SZPpBhzO84qB"
      },
      "outputs": [],
      "source": [
        "inputs = [[char_to_idx[char] for char in user_data[user]['x'][0]] for user in users]\n",
        "targets = [[char_to_idx[char] for char in user_data[user]['y'][0]] for user in users]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL76d_dj86nc"
      },
      "source": [
        "## Creation of TensorDataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "poVRn7mM8_1f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "input_tensors = [torch.tensor(seq) for seq in inputs]\n",
        "target_tensors = [torch.tensor([seq]) for seq in targets]\n",
        "\n",
        "chars = sorted(set(all_texts))\n",
        "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
        "char_to_idx['<pad>'] = len(char_to_idx)\n",
        "idx_to_char = {idx: ch for ch, idx in char_to_idx.items()}\n",
        "\n",
        "padded_inputs = pad_sequence(input_tensors, batch_first=True, padding_value=char_to_idx['<pad>'])\n",
        "\n",
        "target_tensors = torch.cat(target_tensors, dim=0)\n",
        "\n",
        "dataset = TensorDataset(padded_inputs, target_tensors)\n",
        "batch_size = 4\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OekQphTKnWdt"
      },
      "outputs": [],
      "source": [
        "def tensor_to_string(tensor, idx_to_char):\n",
        "    \"\"\"Converte un tensore di indici in una stringa di caratteri.\"\"\"\n",
        "    return ''.join(idx_to_char[idx.item()] for idx in tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "U8NgTC39nYK9"
      },
      "outputs": [],
      "source": [
        "# Function to convert character values into indices\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "def char_to_tensor(characters):\n",
        "    indices = [char_to_idx.get(char, char_to_idx['<pad>']) for char in characters] # Get the index for the character. If not found, use the index for padding.\n",
        "    return torch.tensor(indices, dtype=torch.long)\n",
        "\n",
        "# Prepare the training data_loader\n",
        "# Prepara i dati di test\n",
        "input_tensors = []\n",
        "target_tensors = []\n",
        "for user in data['users']:\n",
        "    for entry, target in zip(data['user_data'][user]['x'], data['user_data'][user]['y']):\n",
        "        input_tensors.append(char_to_tensor(entry))  # Use the full sequence of x\n",
        "        target_tensors.append(char_to_tensor(target))  # Directly use the corresponding y as target\n",
        "\n",
        "# Padding e creazione di DataLoader\n",
        "padded_inputs = pad_sequence(input_tensors, batch_first=True, padding_value=char_to_idx['<pad>'])\n",
        "targets = torch.cat(target_tensors)\n",
        "dataset = TensorDataset(padded_inputs, targets)\n",
        "for elem1, elem2 in dataset:\n",
        "  elem2 = elem2.unsqueeze(0)\n",
        "\n",
        "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HrI7p5-wbvVz"
      },
      "outputs": [],
      "source": [
        "# Prepare the test loader:\n",
        "# Prepare the training data_loader\n",
        "\n",
        "input_tensors = []\n",
        "target_tensors = []\n",
        "for user in test_data['users']:\n",
        "    for entry, target in zip(test_data['user_data'][user]['x'], test_data['user_data'][user]['y']):\n",
        "        input_tensors.append(char_to_tensor(entry))  # Use the full sequence of x\n",
        "        target_tensors.append(char_to_tensor(target))  # Directly use the corresponding y as target\n",
        "\n",
        "# Padding e creazione di DataLoader\n",
        "padded_inputs = pad_sequence(input_tensors, batch_first=True, padding_value=char_to_idx['<pad>'])\n",
        "targets = torch.cat(target_tensors)\n",
        "dataset = TensorDataset(padded_inputs, targets)\n",
        "for elem1, elem2 in dataset:\n",
        "  elem2 = elem2.unsqueeze(0)\n",
        "\n",
        "test_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAz5GpfMl8Mv"
      },
      "source": [
        "## Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bWSl31M6DjPg"
      },
      "outputs": [],
      "source": [
        "global_model = CharLSTM(vocab_size=len(char_to_idx))\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NZV6hBUnH3F"
      },
      "source": [
        "# Evolutionary algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZIvpAtgdnIK8"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from copy import deepcopy\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#constants\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#CRITERION = nn.NLLLoss()\n",
        "#MOMENTUM = 0.9\n",
        "#BATCHSIZE = 64\n",
        "\n",
        "def tournament_selection_weakest(population, tau=2, p_diver=0.05):\n",
        "    \"\"\"\n",
        "    Perform tournament selection to choose parents.\n",
        "    Randomly select tau individuals and choose the weakest one.\n",
        "    Fitness hole to introduce a 5% probability of choosing the fittest individual.\n",
        "\n",
        "\n",
        "    :param population: List of Individuals.\n",
        "    :param tau: Number of individuals to select.\n",
        "    :param p_diver: Probability of choosing the worst individual in the tournament, done for the fitness hole.\n",
        "    :return: Selected Individual.\n",
        "    \"\"\"\n",
        "    participants = random.sample(population, tau)\n",
        "    if random.random() < p_diver:\n",
        "        winner = max(participants, key=lambda ind: ind.fitness)\n",
        "    else:\n",
        "      winner = min(participants, key=lambda ind: ind.fitness)\n",
        "    return deepcopy(winner)\n",
        "\n",
        "def tournament_selection_fittest(population, tau=2, p_diver=0.05):\n",
        "    \"\"\"\n",
        "    Perform tournament selection to choose parents.\n",
        "    Randomly select tau individuals and choose the best one.\n",
        "    Fitness hole to introduce a 5% probability of choosing the weakest individual.\n",
        "\n",
        "\n",
        "    :param population: List of Individuals.\n",
        "    :param tau: Number of individuals to select.\n",
        "    :param p_diver: Probability of choosing the worst individual in the tournament, done for the fitness hole.\n",
        "    :return: Selected Individual.\n",
        "    \"\"\"\n",
        "    participants = random.sample(population, tau)\n",
        "    if random.random() < p_diver:\n",
        "        winner = min(participants, key=lambda ind: ind.fitness)\n",
        "    else:\n",
        "      winner = max(participants, key=lambda ind: ind.fitness)\n",
        "    return deepcopy(winner)\n",
        "\n",
        "\n",
        "def client_size(individual, client_sizes):\n",
        "    \"\"\"\n",
        "    Computes the number of total samples for individual\n",
        "    \"\"\"\n",
        "    val = 0\n",
        "    for client in individual.genome:\n",
        "        val += client_sizes[client]\n",
        "    return val\n",
        "\n",
        "\n",
        "def EA_algorithm(generations, population_size, num_clients, num_classes, crossover_probability, dataset, lr, wd, criterion, char_to_idx, total_clients):\n",
        "    \"\"\"\n",
        "    Perform the Evolutionary Algorithm (EA) to optimize the selection of clients.\n",
        "    The EA consists of the following steps:\n",
        "    1. Initialization: Create a population of individuals.\n",
        "    2. Evaluation: Compute the fitness of each individual.\n",
        "    3. Selection: Choose parents based on their fitness.\n",
        "    4. Offspring to create the new population (generational model).\n",
        "    6. Repeat from step 2 maximum iterations.\n",
        "\n",
        "    :param generations: Number of generations to run the algorithm.\n",
        "    :param population_size: Number of individuals in the population.\n",
        "    :param num_clients: clients selected by each individual.\n",
        "    :param num_classes: Number of classes for each client (iid or non-iid).\n",
        "    :param crossover_probability: Probability of crossover for each individual.\n",
        "    :param dataset: The dataset to be used for training.\n",
        "    :param lr: The learning rate to be used for training.\n",
        "    :param wd: The weight decay to be used for training.\n",
        "    :param criterion: The loss function to use.\n",
        "    :param char_to_idx: to switch between character and integer encoding of them.\n",
        "    :param total_clients: total number of clients in the loaded database.\n",
        "\n",
        "\n",
        "    :return global_model: The global model obtained after the EA.\n",
        "    :return training_accuracies: The training loss of the global model at each generation.\n",
        "    :return training_losses: The training accuracy of the global model at each generation.\n",
        "    :return client_selection_count: The number of times each client was selected in the population.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "    # mantain memory of the number of times each client have been selected:\n",
        "    client_selection_count = [0]*total_clients\n",
        "    #print(\"num clients:,\", total_clients)\n",
        "    best_model_state = None\n",
        "    best_train_loss = float('inf')\n",
        "\n",
        "\n",
        "    # Initialize the population\n",
        "    # Shuffle clients before assigning them\n",
        "    all_clients = list(range(total_clients))\n",
        "    random.shuffle(all_clients)\n",
        "\n",
        "    #No individual, at the beginning, will select a client twice\n",
        "    population = [\n",
        "        Individual(genome=all_clients[i * num_clients:(i + 1) * num_clients], total_clients=total_clients)\n",
        "        for i in range(population_size)\n",
        "    ]\n",
        "    #population = [Individual(genome=random.sample(range(100), k=num_clients)) for _ in range(population_size)]\n",
        "    model = CharLSTM(vocab_size=len(char_to_idx))\n",
        "\n",
        "    server = Server(model,DEVICE, char_to_idx)\n",
        "\n",
        "    shards = server.sharding(dataset)\n",
        "    client_sizes = [len(shard) for shard in shards]\n",
        "\n",
        "    for gen in range(generations):\n",
        "    #for gen in range(generations):\n",
        "        # For each of them apply the fed_avg algorithm:\n",
        "        param_list = []\n",
        "        averages_acc = []\n",
        "        average_loss = []\n",
        "        for individual in population:\n",
        "            #Update the client selection count\n",
        "            for client in individual.genome:\n",
        "                client_selection_count[client] += 1\n",
        "\n",
        "            resulting_model, acc_res, loss_res = server.train_federated(criterion, lr, MOMENTUM, BATCH_SIZE, wd, individual, shards)\n",
        "            param_list.append(resulting_model)\n",
        "            averages_acc.append(acc_res)\n",
        "            average_loss.append(loss_res)\n",
        "\n",
        "\n",
        "        #Here we should average all the models to obtain the global model\n",
        "        averaged_model,  train_loss, train_accuracy = server.fedavg_aggregate(param_list, [client_size(i, client_sizes) for i in population], average_loss, averages_acc)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        # Update the model with the result of the average:\n",
        "        model.load_state_dict(averaged_model)\n",
        "        #Just to be sure:\n",
        "        server.global_model.load_state_dict(averaged_model)\n",
        "\n",
        "        if train_loss < best_train_loss:\n",
        "            best_train_loss = train_loss\n",
        "            best_model_state = deepcopy(model.state_dict())\n",
        "\n",
        "        offspring = []\n",
        "        #Offspring-> offspring size is the same as population size\n",
        "        elite = sorted(population, key=lambda ind: ind.fitness, reverse=True)[0]\n",
        "        offspring.append(elite) #Keep the best individual\n",
        "        for j in range(population_size-1):\n",
        "            # Crossover\n",
        "            if random.random() < crossover_probability:\n",
        "                parent1 = tournament_selection_fittest(population)\n",
        "                parent2 = tournament_selection_fittest(population)\n",
        "                offspring.append(Individual.crossover(parent1, parent2))\n",
        "            else:\n",
        "                #Mutation\n",
        "                parent = tournament_selection_weakest(population)\n",
        "                parent.mutation()\n",
        "                offspring.append(parent)\n",
        "\n",
        "        # Replace the population with the new offspring\n",
        "        population = offspring\n",
        "\n",
        "    model.load_state_dict(best_model_state)\n",
        "    return model, train_accuracies, train_losses, client_selection_count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XHfjoldYCeHV"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "lr = 1.0\n",
        "wd = 0.0001\n",
        "generations = 200\n",
        "population_size = 10\n",
        "num_clients = 2\n",
        "num_classes = 100\n",
        "crossover_probability = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgZaYRekNo5F",
        "outputId": "5aa3c85e-1cd5-414b-89d5-84b5a3df0a89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n"
          ]
        }
      ],
      "source": [
        "print(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0VkL5U5pjm7",
        "outputId": "ea7eee4e-d83e-48ec-aba5-5e1465a35795"
      },
      "outputs": [],
      "source": [
        "#Best lr and wd found for iid federated baseline: lr=0.1, wd=0.001\n",
        "global_model = CharLSTM(vocab_size=len(char_to_idx))\n",
        "global_model,train_accuracies,train_losses,client_selection_count=EA_algorithm(generations=generations,population_size=population_size,num_clients=num_clients,num_classes = num_classes, crossover_probability = crossover_probability, dataset= data, lr =lr , wd = wd, criterion = criterion, char_to_idx=char_to_idx, total_clients=NUM_CLIENTS)\n",
        "test_accuracy, test_loss = test(global_model, test_loader, criterion, DEVICE)\n",
        "print(\"Test accuracy: \",test_accuracy)\n",
        "#plot_client_selection(client_selection_count,\"EA_iid_client_selection.png\")\n",
        "#save_data(global_model,val_accuracies,val_losses,train_accuracies,train_losses,client_selection_count,\"EA_iid.pth\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
