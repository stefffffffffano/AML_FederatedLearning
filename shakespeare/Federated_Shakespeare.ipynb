{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usjY0Bcpq_KW"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6AYtngaiB0cJ"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import io\n",
        "import json\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.backends import cudnn\n",
        "import time\n",
        "import numpy as np\n",
        "from statistics import mean\n",
        "import torch.optim as optim\n",
        "from copy import deepcopy\n",
        "import logging\n",
        "from torch.utils.data import Subset\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog\n",
        "from Client import Client\n",
        "from Server import Server\n",
        "from Model import CharLSTM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ip3R30psZxR"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjnl6b5eDPMY",
        "outputId": "99a350d5-8800-462d-d8ec-1424eddc7c19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# Constants for FL training\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(DEVICE)\n",
        "FRACTION_CLIENTS = 0.1  # Fraction of clients selected per round (C)\n",
        "criterion =  nn.CrossEntropyLoss()\n",
        "BATCH_SIZE = 100  # Batch size for local training\n",
        "MOMENTUM = 0.0  # Momentum for SGD optimizer\n",
        "LOG_FREQUENCY = 10 # Frequency of logging training progress"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVSI_pV5lfmR"
      },
      "source": [
        "# DataLoading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ6fgnHwa0Ai"
      },
      "source": [
        "We must import the dataset manually since it is taken by the LEAF project.\n",
        "\n",
        "So far the project is to go on the data folder of shakespeare and:\n",
        "1. ./get_data.sh inside the preprocess folder\n",
        "2. ./data_to_json.sh\n",
        "3. cd ..\n",
        "3. ././preprocess.sh -s niid --sf 0.2 -k 0 -t sample -tf 0.8 [depending on the preferencies]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Please upload the training dataset provided by LEAF here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "root = tk.Tk()\n",
        "#root.withdraw()\n",
        "\n",
        "file_path = filedialog.askopenfilename(filetypes=[(\"JSON files\", \"*.json\")])\n",
        "\n",
        "if file_path:\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "            \n",
        "root.destroy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Please upload the test dataset provided by LEAF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "root = tk.Tk()\n",
        "#root.withdraw()\n",
        "\n",
        "file_path = filedialog.askopenfilename(filetypes=[(\"JSON files\", \"*.json\")])\n",
        "\n",
        "if file_path:\n",
        "    with open(file_path, 'r') as file:\n",
        "        test_data = json.load(file)\n",
        "            \n",
        "root.destroy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbR2pJ1WeuLM",
        "outputId": "27418e45-c1d2-41a1-d467-28360ac6dc7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of clients: 100\n"
          ]
        }
      ],
      "source": [
        "num_clients = len(data['users'])\n",
        "print(\"Number of clients:\", num_clients)\n",
        "NUM_CLIENTS = num_clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "i9UliC2qnQUe"
      },
      "outputs": [],
      "source": [
        "users = data['users']\n",
        "num_samples = data['num_samples']\n",
        "user_data = data['user_data']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Y1an7TUynSM3"
      },
      "outputs": [],
      "source": [
        "all_texts = ''.join([''.join(seq) for user in users for seq in user_data[user]['x']])\n",
        "chars = sorted(set(all_texts))\n",
        "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
        "\n",
        "# Add the padding character\n",
        "char_to_idx['<pad>'] = len(char_to_idx)\n",
        "idx_to_char = {idx: ch for ch, idx in char_to_idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDItE3pL82K7"
      },
      "source": [
        "## Convert data into indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SZPpBhzO84qB"
      },
      "outputs": [],
      "source": [
        "inputs = [[char_to_idx[char] for char in user_data[user]['x'][0]] for user in users]\n",
        "targets = [[char_to_idx[char] for char in user_data[user]['y'][0]] for user in users]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL76d_dj86nc"
      },
      "source": [
        "## Creation of TensorDataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "poVRn7mM8_1f"
      },
      "outputs": [],
      "source": [
        "input_tensors = [torch.tensor(seq) for seq in inputs]\n",
        "target_tensors = [torch.tensor([seq]) for seq in targets]\n",
        "\n",
        "chars = sorted(set(all_texts))\n",
        "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
        "char_to_idx['<pad>'] = len(char_to_idx)\n",
        "idx_to_char = {idx: ch for ch, idx in char_to_idx.items()}\n",
        "\n",
        "padded_inputs = pad_sequence(input_tensors, batch_first=True, padding_value=char_to_idx['<pad>'])\n",
        "\n",
        "target_tensors = torch.cat(target_tensors, dim=0)\n",
        "\n",
        "dataset = TensorDataset(padded_inputs, target_tensors)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OekQphTKnWdt"
      },
      "outputs": [],
      "source": [
        "#for testing porpouses\n",
        "def tensor_to_string(tensor, idx_to_char):\n",
        "    \"\"\"Convert a tensor of indices in a string of characters.\"\"\"\n",
        "    return ''.join(idx_to_char[idx.item()] for idx in tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "U8NgTC39nYK9"
      },
      "outputs": [],
      "source": [
        "# Function to convert character values into indices\n",
        "def char_to_tensor(characters):\n",
        "    indices = [char_to_idx.get(char, char_to_idx['<pad>']) for char in characters] # Get the index for the character. If not found, use the index for padding.\n",
        "    return torch.tensor(indices, dtype=torch.long)\n",
        "\n",
        "# Prepare the training data_loader\n",
        "input_tensors = []\n",
        "target_tensors = []\n",
        "for user in data['users']:\n",
        "    for entry, target in zip(data['user_data'][user]['x'], data['user_data'][user]['y']):\n",
        "        input_tensors.append(char_to_tensor(entry))  # Use the full sequence of x\n",
        "        target_tensors.append(char_to_tensor(target))  # Directly use the corresponding y as target\n",
        "\n",
        "# Padding e creazione di DataLoader\n",
        "padded_inputs = pad_sequence(input_tensors, batch_first=True, padding_value=char_to_idx['<pad>'])\n",
        "targets = torch.cat(target_tensors)\n",
        "dataset = TensorDataset(padded_inputs, targets)\n",
        "# for elem1, elem2 in dataset:\n",
        "#   elem2 = elem2.unsqueeze(0)\n",
        "\n",
        "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5HznZhC1OPx",
        "outputId": "521d10a9-8eca-428e-edeb-bd1fbeccff16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "253569\n"
          ]
        }
      ],
      "source": [
        "# len of the trainig split:\n",
        "print(len(data_loader.dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HrI7p5-wbvVz"
      },
      "outputs": [],
      "source": [
        "# Prepare the training data_loader\n",
        "input_tensors = []\n",
        "target_tensors = []\n",
        "for user in test_data['users']:\n",
        "    for entry, target in zip(test_data['user_data'][user]['x'], test_data['user_data'][user]['y']):\n",
        "        input_tensors.append(char_to_tensor(entry))  # Use the full sequence of x\n",
        "        target_tensors.append(char_to_tensor(target))  # Directly use the corresponding y as target\n",
        "\n",
        "# Padding e creazione di DataLoader\n",
        "padded_inputs = pad_sequence(input_tensors, batch_first=True, padding_value=char_to_idx['<pad>'])\n",
        "targets = torch.cat(target_tensors)\n",
        "dataset = TensorDataset(padded_inputs, targets)\n",
        "# for elem1, elem2 in dataset:\n",
        "#   elem2 = elem2.unsqueeze(0)\n",
        "\n",
        "test_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deLbT6wB1T06",
        "outputId": "9003e9a4-9f2e-4b86-f71e-eb032edcc3db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42869\n"
          ]
        }
      ],
      "source": [
        "# len of the test split:\n",
        "print(len(test_loader.dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMatdM49s63b"
      },
      "source": [
        "# Model inizialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bWSl31M6DjPg"
      },
      "outputs": [],
      "source": [
        "global_model = CharLSTM(vocab_size=len(char_to_idx))\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPy9RrSMtB1U"
      },
      "source": [
        "# Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CSdo3O9eoBFv"
      },
      "outputs": [],
      "source": [
        "DIR = '/content/drive/MyDrive/colab_plots/'\n",
        "\n",
        "\"\"\"\n",
        "Utility function used both in the centralized and federated learning\n",
        "Computes the accuracy and the loss on the validation/test set depending on the dataloader passed\n",
        "\"\"\"\n",
        "def evaluate(model, dataloader, criterion, DEVICE):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    running_corrects = 0\n",
        "    total_samples = 0  # Total samples counter\n",
        "    losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, targets in dataloader:\n",
        "            data = data.to(DEVICE)\n",
        "            targets = targets.to(DEVICE)\n",
        "            hidden = model.init_hidden(data.size(0))\n",
        "            hidden = (hidden[0].to(DEVICE), hidden[1].to(DEVICE))\n",
        "            outputs, _ = model(data, hidden)\n",
        "            outputs_flat = outputs.view(-1, model.vocab_size)\n",
        "            targets_flat = targets.view(-1)\n",
        "\n",
        "            loss = criterion(outputs_flat, targets_flat)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            _, preds = outputs_flat.max(1)\n",
        "            #running_corrects += torch.sum(preds == targets_flat).item()\n",
        "            running_corrects += (preds == targets_flat).sum().item()\n",
        "            total_samples += targets_flat.size(0)\n",
        "\n",
        "    accuracy = (running_corrects / total_samples) * 100\n",
        "    return accuracy, sum(losses) / len(losses)\n",
        "\n",
        "\n",
        "def test(global_model, test_loader, criterion, DEVICE):\n",
        "    \"\"\"\n",
        "    Evaluate the global model on the test dataset.\n",
        "\n",
        "    Args:\n",
        "        global_model (nn.Module): The global model to be evaluated.\n",
        "        test_loader (DataLoader): DataLoader for the test dataset.\n",
        "\n",
        "    Returns:\n",
        "        float: The accuracy of the model on the test dataset.\n",
        "        float: The loss of the model on the test dataset.\n",
        "    \"\"\"\n",
        "    test_accuracy, loss = evaluate(global_model, test_loader, criterion, DEVICE)\n",
        "    return test_accuracy, loss\n",
        "\n",
        "\n",
        "\n",
        "def save_data(global_model, train_accuracies, train_losses,client_count, file_name):\n",
        "    \"\"\"\n",
        "    Save the global model, train_accuracies,train_losses and client_count to a file.\n",
        "\n",
        "    Args:\n",
        "        global_model (nn.Module): The global model to be saved.\n",
        "        train_accuracies (list): List of training accuracies.\n",
        "        train_losses (list): List of training losses.\n",
        "        file_name (str): Name of the file to save the data.\n",
        "    \"\"\"\n",
        "    # Fixed base directory\n",
        "    directory = DIR + '/trained_models/'\n",
        "    # Ensure the base directory exists\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "    # Complete path for the file\n",
        "    file_path = os.path.join(directory, file_name)\n",
        "\n",
        "    # Save all data (model state and metrics) into a dictionary\n",
        "    save_dict = {\n",
        "        'model_state': global_model.state_dict(),\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'train_losses': train_losses,\n",
        "        'client_count': client_count\n",
        "    }\n",
        "\n",
        "    # Save the dictionary to the specified file\n",
        "    torch.save(save_dict, file_path)\n",
        "    print(f\"Data saved successfully to {file_path}\")\n",
        "\n",
        "def load_data(model, file_name):\n",
        "    \"\"\"\n",
        "    Load the model weights and metrics from a file.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The model to load the weights into.\n",
        "        file_name (str): Name of the file to load the data from.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the model, train_accuracies train_losses and client_count.\n",
        "    \"\"\"\n",
        "    # Fixed base directory\n",
        "    directory = DIR+ 'trained_models/'\n",
        "    # Complete path for the file\n",
        "    file_path = os.path.join(directory, file_name)\n",
        "\n",
        "    # Load the saved data from the specified file\n",
        "    save_dict = torch.load(file_path)\n",
        "\n",
        "    # Load the model state\n",
        "    model.load_state_dict(save_dict['model_state'])\n",
        "\n",
        "    # Extract the metrics\n",
        "    train_accuracies = save_dict['train_accuracies']\n",
        "    train_losses = save_dict['train_losses']\n",
        "    client_count = save_dict['client_count']\n",
        "\n",
        "    print(f\"Data loaded successfully from {file_path}\")\n",
        "\n",
        "    return model, train_accuracies, train_losses,client_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57d-hbzJBW0G"
      },
      "source": [
        "# Training cycle and testing results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ-REjRABY3F",
        "outputId": "64573dfc-1ef1-4257-9553-d469ac19531c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running experiment: local_steps=4\n"
          ]
        }
      ],
      "source": [
        "lr = 1.0\n",
        "wd = 0.0001\n",
        "'''\n",
        "These hyperparameters are taken from:\n",
        "Acar, Durmus Alp Emre, et al. \"Federated learning based on dynamic regularization.\" arXiv preprint arXiv:2111.04263 (2021).\n",
        "\n",
        "Notice infact that the leaf version of the Shakespeare dataset doesn't come with a linked validation dataset to\n",
        "choose the most accurate hyperparameters.\n",
        "'''\n",
        "\n",
        "local_steps =4\n",
        "LOCAL_STEPS_VALUES = [4, 8, 16]  # Values for J (number of local steps)\n",
        "NUM_RUNDS = {4: 600, 8: 300, 16:150}\n",
        "print(f\"Running experiment: local_steps={local_steps}\")\n",
        "global_model = CharLSTM(vocab_size=len(char_to_idx))\n",
        "server = Server(global_model, DEVICE, char_to_idx)\n",
        "\n",
        "    #tuning_rounds = int(NUM_RUNDS[local_steps]/20)\n",
        "    #best_lr, best_wd = to be manually set\n",
        "\n",
        "global_model, train_accuracies, train_losses, client_selection_count = server.train_federated(\n",
        "        criterion, data,\n",
        "        num_clients=NUM_CLIENTS,\n",
        "        rounds=NUM_RUNDS[local_steps], lr=lr, momentum=MOMENTUM,\n",
        "        batchsize=BATCH_SIZE, wd=wd, C=FRACTION_CLIENTS,\n",
        "        local_steps=local_steps, log_freq=100,\n",
        "        detailed_print=True, gamma=None  # No skewed sampling for this experiment\n",
        ")\n",
        "\n",
        "# Testing and plotting\n",
        "test_accuracy, test_loss = test(global_model, test_loader, criterion, DEVICE)\n",
        "#plot_metrics(train_accuracies, train_losses, f\"Federated_scaled_LR_{lr}_WD_{wd}.png\")\n",
        "print(f\"Test accuracy for local_steps={local_steps}: {test_accuracy}\")\n",
        "\n",
        "# Save data for future analysis\n",
        "#save_data(global_model, train_accuracies, train_losses, client_selection_count, f\"Federated_LR_{lr}_WD_{wd}_j_{local_steps}.pth\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
