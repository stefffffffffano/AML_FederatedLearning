# Optimizing Client Selection in Federated Learning with Evolutionary Algorithms  

## ğŸ“– Overview  

Federated Learning (FL) is a decentralized approach to machine learning where models are trained across multiple devices while keeping data localized. This project investigates **client selection strategies** in FL using **Evolutionary Algorithms (EAs)** to improve convergence and reduce communication overhead.  

We conduct experiments on **two datasets**:  
- ğŸ“¸ **CIFAR-100** â€“ Image classification task  
- ğŸ­ **Shakespeare** â€“ Character-level language modeling  

The experiments include **centralized** and **federated** settings to provide a comparative analysis of Federated Learning performance.  

---

## ğŸ“‚ Repository Structure  

The repository is structured into two main dataset-specific directories:  

### ğŸ”¹ `cifar100/`  
- `data/cifar100/` â†’ Data loading utilities  
- `models/` â†’ Model definitions  
- `plots_centralized/`, `plots_federated/` â†’ Experiment results  
- `trained_models/` â†’ Saved models  
- `utils/` â†’ Utility scripts  
- `Client.py` â†’ Client-side logic for FL  
- `Server.py` â†’ Server-side logic for FL  
- `federated_notebook.ipynb` â†’ Jupyter notebook for FL experiments  
- `train_centralized.ipynb` â†’ Jupyter notebook for centralized experiments  
- `Report.md` â†’ Detailed results and analysis  
- `personal_contribution/` â†’ **Implementation of Evolutionary Algorithms (EA) for client selection (Jupyter notebook: `Experiments.ipynb`)**  

### ğŸ”¹ `shakespeare/`  
- `LEAF_data/` â†’ Dataset preprocessing scripts from **LEAF Benchmark**  
- `trained_models/` â†’ Saved models  
- `plot_centralized/`, `plot_federated/` â†’ Experiment results  
- `Client.py` â†’ Client-side logic  
- `Server.py` â†’ Server-side logic  
- `Model.py` â†’ LSTM model for character prediction  
- `Centralized_Shakespeare.ipynb` â†’ Centralized experiments  
- `Federated_Shakespeare.ipynb` â†’ Federated experiments  
- `Report.md` â†’ Results and insights  
- `personal_contribution/` â†’ **Implementation of Evolutionary Algorithms (EA) for client selection (Jupyter notebook: `Experiments.ipynb`)**  
---

## ğŸ¯ Personal Contribution Methodology  

We propose an **evolutionary-based client selection strategy** to tackle statistical and system heterogeneity in FL.  

### âš¡ **Key Contributions**  
âœ… **Adaptive Client Selection**: Using EAs to select high-loss clients for better model convergence  
âœ… **Fairness Considerations**: Ensuring diverse client participation without exposing private data  

---

## ğŸ“Š Experimental Setup  

### ğŸ“Œ **Datasets**  
1ï¸âƒ£ **CIFAR-100**: Standard image classification dataset  
2ï¸âƒ£ **Shakespeare** (from [LEAF Benchmark](https://leaf.cmu.edu/)): Character-level text prediction  

### ğŸ— **Federated Learning Setup**  
- **Client-Server Architecture** with multiple clients updating local models  
- **Heterogeneous Data Distribution** simulating real-world FL scenarios  
- **Comparison with Baseline Strategies**:  
  - Random client selection  
  - Uniform sampling  
  - Proposed **EA-based selection**  

### ğŸ”§ **Hyperparameter Tuning**  
- Different **learning rates (lr)**, **weight decays (wd)**, and **schedulers**  
- Details available in `Report.md`  

---

## ğŸ“ˆ Results  

ğŸ”¹ **Federated vs. Centralized Performance**  
- Evaluated model accuracy & loss trends for different settings  
- Comparison of FL client selection strategies  

ğŸ”¹ **Impact of Client Selection**  
- Improved convergence speed with EA-based selection  
- Better utilization of computational resources  

ğŸ”¹ **Plots & Visualizations**  
- Accuracy & loss curves saved in `plots_federated/` and `plots_centralized/`  

---

## ğŸš€ Getting Started  

### ğŸ”¹ **1. Clone the repository**  
```bash
git clone https://github.com/your-repo.git
cd your-repo
```

### ğŸ”¹ **2. Set up the environment**  
```bash
python -m venv env
source env/bin/activate  # On Windows: env\Scripts\activate
pip install -r requirements.txt
```

### ğŸ”¹ **3. Run Experiments**  
#### ğŸ–¼ CIFAR-100  
- **Centralized Training:**  
  ```bash
  jupyter notebook cifar100/train_centralized.ipynb
  ```
- **Federated Learning:**  
  ```bash
  jupyter notebook cifar100/federated_notebook.ipynb
  ```

#### ğŸ­ Shakespeare  
- **Centralized Training:**  
  ```bash
  jupyter notebook shakespeare/Centralized_Shakespeare.ipynb
  ```
- **Federated Learning:**  
  ```bash
  jupyter notebook shakespeare/Federated_Shakespeare.ipynb
  ```

---

## ğŸ“š References  

1ï¸âƒ£ **LEAF Benchmark**: Caldas, Sebastian, et al. *"Leaf: A benchmark for federated settings."* arXiv preprint arXiv:1812.01097 (2018).  
2ï¸âƒ£ **Federated Optimization**: Reddi, Sashank, et al. *"Adaptive Federated Optimization."* 2021.  

---

## ğŸ¯ Future Work  

ğŸ”¹ Apply the method to **more complex datasets**  
ğŸ”¹ Extend selection strategies with **reinforcement learning**  
ğŸ”¹ Optimize for **mobile and edge computing** scenarios  

---

## ğŸ¤ Contributions  

Contributions are welcome! Feel free to fork the repo and submit pull requests. ğŸš€  

---

## ğŸ›  Contact  

**Authors:**  
- ğŸ§‘â€ğŸ’» Luca Dadone  
- ğŸ§‘â€ğŸ’» Stefano Fumero  
- ğŸ§‘â€ğŸ’» Andrea Mirenda  

ğŸ“© For any inquiries, please reach out to the authors.  

