{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefffffffffano/AML_FederatedLearning/blob/main/Federated_CIFAR_100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6AYtngaiB0cJ"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjnl6b5eDPMY",
        "outputId": "44559d36-fe0f-4ac6-9284-fd8523e7db7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Constants for FL training\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(DEVICE)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "NUM_CLIENTS = 100  # Total number of clients in the federation\n",
        "FRACTION_CLIENTS = 0.1  # Fraction of clients selected per round (C)\n",
        "LOCAL_STEPS = 4  # Number of local steps (J)\n",
        "GLOBAL_ROUNDS = 2000  # Total number of communication rounds\n",
        "\n",
        "BATCH_SIZE = 64  # Batch size for local training\n",
        "MOMENTUM = 0\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/colab_checkpoints/'\n",
        "LOG_FREQUENCY = 10  # Frequency of logging training progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7l_1QspQNQS-"
      },
      "outputs": [],
      "source": [
        "!rm -r {CHECKPOINT_DIR}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eYwAQsg2DSws"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class CIFAR100DataLoader:\n",
        "    def __init__(self, batch_size=64, validation_split=0.1, download=True, num_workers=4, pin_memory=True):\n",
        "        self.batch_size = batch_size\n",
        "        self.validation_split = validation_split\n",
        "        self.download = download\n",
        "        self.num_workers = num_workers\n",
        "        self.pin_memory = pin_memory\n",
        "\n",
        "        # Define transformations\n",
        "        self.train_transform = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
        "        ])\n",
        "\n",
        "        self.test_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
        "        ])\n",
        "\n",
        "        # Load datasets\n",
        "        self.train_loader, self.val_loader, self.test_loader = self._prepare_loaders()\n",
        "\n",
        "    def _prepare_loaders(self):\n",
        "        # Load the full training dataset\n",
        "        full_trainset = datasets.CIFAR100(root='./data', train=True, download=self.download, transform=self.train_transform)\n",
        "\n",
        "        # Split indices for training and validation\n",
        "        indexes = list(range(len(full_trainset)))\n",
        "        train_indexes, val_indexes = train_test_split(\n",
        "            indexes,\n",
        "            train_size=1 - self.validation_split,\n",
        "            test_size=self.validation_split,\n",
        "            random_state=42,\n",
        "            stratify=full_trainset.targets,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        # Create training and validation subsets\n",
        "        train_dataset = Subset(full_trainset, train_indexes)\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset, batch_size=self.batch_size, shuffle=True,\n",
        "            num_workers=self.num_workers, pin_memory=self.pin_memory\n",
        "        )\n",
        "\n",
        "        full_trainset_val = datasets.CIFAR100(root='./data', train=True, download=self.download, transform=self.test_transform)\n",
        "        val_dataset = Subset(full_trainset_val, val_indexes)\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset, batch_size=self.batch_size, shuffle=False,\n",
        "            num_workers=self.num_workers, pin_memory=self.pin_memory\n",
        "        )\n",
        "\n",
        "        # Load the test dataset\n",
        "        testset = datasets.CIFAR100(root='./data', train=False, download=self.download, transform=self.test_transform)\n",
        "        test_loader = DataLoader(\n",
        "            testset, batch_size=self.batch_size, shuffle=False,\n",
        "            num_workers=self.num_workers, pin_memory=self.pin_memory\n",
        "        )\n",
        "\n",
        "        return train_loader, val_loader, test_loader\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Allows iteration over all loaders for unified access.\"\"\"\n",
        "        return iter([self.train_loader, self.val_loader, self.test_loader])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uqI29GCvE8F_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from statistics import mean\n",
        "import torch.nn as nn\n",
        "\n",
        "\"\"\"\n",
        "Utility function used both in the centralized and federated learning\n",
        "Computes the accuracy and the loss on the validation/test set depending on the dataloader passed\n",
        "\"\"\"\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "criterion = nn.NLLLoss()# our loss function for classification tasks on CIFAR-100\n",
        "def evaluate(model, dataloader):\n",
        "    with torch.no_grad():\n",
        "        model.train(False) # Set Network to evaluation mode\n",
        "        running_corrects = 0\n",
        "        losses = []\n",
        "        for data, targets in dataloader:\n",
        "            data = data.to(DEVICE)        # Move the data to the GPU\n",
        "            targets = targets.to(DEVICE)  # Move the targets to the GPU\n",
        "            # Forward Pass\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, targets)\n",
        "            losses.append(loss.item())\n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            # Update Corrects\n",
        "            running_corrects += torch.sum(preds == targets.data).data.item()\n",
        "            # Calculate Accuracy\n",
        "            accuracy = running_corrects / float(len(dataloader.dataset))\n",
        "\n",
        "    return accuracy*100, mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eNOz0NNeDaX6"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\"\"\"\n",
        "Model architecture for the CIFAR-100 dataset.\n",
        "The model is based on the LeNet-5 architecture with some modifications.\n",
        "Reference: Hsu et al., Federated Visual Classification with Real-World Data Distribution, ECCV 2020\n",
        "\n",
        "CNN similar to LeNet5 which has two 5×5, 64-channel convolution layers, each precedes a 2×2\n",
        "max-pooling layer, followed by two fully-connected layers with 384 and 192\n",
        "channels respectively and finally a softmax linear classifier\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv_layer = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 64, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(64 * 5 * 5, 384),  # Updated to be consistent with data augmentation\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(384, 192),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(192, 100)  # 100 classes for CIFAR-100\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layer(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output of the conv layers\n",
        "        x = self.fc_layer(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sfb3t6fREwje"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import json\n",
        "\n",
        "# Ensure the checkpoint directory exists, creating it if necessary\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, hyperparameters, subfolder=\"\", checkpoint_data=None):\n",
        "    \"\"\"\n",
        "    Saves the model checkpoint and removes the previous one if it exists.\n",
        "\n",
        "    Arguments:\n",
        "    model -- The model whose state is to be saved.\n",
        "    optimizer -- The optimizer whose state is to be saved (can be None).\n",
        "    epoch -- The current epoch of the training process.\n",
        "    hyperparameters -- A string representing the model's hyperparameters for file naming.\n",
        "    subfolder -- Optional subfolder within the checkpoint directory to save the checkpoint.\n",
        "    checkpoint_data -- Data to save in a JSON file (e.g., training logs).\n",
        "    \"\"\"\n",
        "    # Define the path for the subfolder where checkpoints will be stored\n",
        "    subfolder_path = os.path.join(CHECKPOINT_DIR, subfolder)\n",
        "    # Create the subfolder if it doesn't exist\n",
        "    os.makedirs(subfolder_path, exist_ok=True)\n",
        "\n",
        "    # Construct filenames for both the model checkpoint and the associated JSON file\n",
        "    filename = f\"model_epoch_{epoch}_params_{hyperparameters}.pth\"\n",
        "    filepath = os.path.join(subfolder_path, filename)\n",
        "    filename_json = f\"model_epoch_{epoch}_params_{hyperparameters}.json\"\n",
        "    filepath_json = os.path.join(subfolder_path, filename_json)\n",
        "\n",
        "    # Define the filenames for the previous checkpoint files, to remove them if necessary\n",
        "    previous_filepath = os.path.join(subfolder_path, f\"model_epoch_{epoch - 1}_params_{hyperparameters}.pth\")\n",
        "    previous_filepath_json = os.path.join(subfolder_path, f\"model_epoch_{epoch - 1}_params_{hyperparameters}.json\")\n",
        "\n",
        "    # Remove the previous checkpoint if it exists, but only for epochs greater than 1\n",
        "    if epoch > 1 and os.path.exists(previous_filepath):\n",
        "        os.remove(previous_filepath)\n",
        "        os.remove(previous_filepath_json)\n",
        "\n",
        "    # Prepare the checkpoint data dictionary\n",
        "    checkpoint = {'model_state_dict': model.state_dict(), 'epoch': epoch}\n",
        "    # If an optimizer is provided, save its state as well\n",
        "    if optimizer is not None:\n",
        "        checkpoint['optimizer_state_dict'] = optimizer.state_dict()\n",
        "\n",
        "    # Save the model and optimizer (if provided) state dictionary to the checkpoint file\n",
        "    torch.save(checkpoint, filepath)\n",
        "    print(f\"Checkpoint saved: {filepath}\")\n",
        "\n",
        "    # If additional data (e.g., training logs) is provided, save it to a JSON file\n",
        "    if checkpoint_data:\n",
        "        with open(filepath_json, 'w') as json_file:\n",
        "            json.dump(checkpoint_data, json_file, indent=4)\n",
        "\n",
        "def load_checkpoint(model, optimizer, hyperparameters, subfolder=\"\"):\n",
        "    \"\"\"\n",
        "    Loads the latest checkpoint available based on the specified hyperparameters.\n",
        "\n",
        "    Arguments:\n",
        "    model -- The model whose state will be updated from the checkpoint.\n",
        "    optimizer -- The optimizer whose state will be updated from the checkpoint (can be None).\n",
        "    hyperparameters -- A string representing the model's hyperparameters for file naming.\n",
        "    subfolder -- Optional subfolder within the checkpoint directory to look for checkpoints.\n",
        "\n",
        "    Returns:\n",
        "    The next epoch to resume from and the associated JSON data if available.\n",
        "    \"\"\"\n",
        "    # Define the path to the subfolder where checkpoints are stored\n",
        "    subfolder_path = os.path.join(CHECKPOINT_DIR, subfolder)\n",
        "\n",
        "    # If the subfolder doesn't exist, print a message and start from epoch 1\n",
        "    if not os.path.exists(subfolder_path):\n",
        "        print(\"No checkpoint found, starting from epoch 1.\")\n",
        "        return 1, None  # Epoch starts from 1\n",
        "\n",
        "    # Search for checkpoint files in the subfolder that match the hyperparameters\n",
        "    files = [f for f in os.listdir(subfolder_path) if f\"params_{hyperparameters}\" in f and f.endswith('.pth')]\n",
        "\n",
        "    # If checkpoint files are found, load the one with the highest epoch number\n",
        "    if files:\n",
        "        latest_file = max(files, key=lambda x: int(x.split('_')[2]))  # Find the latest epoch file\n",
        "        filepath = os.path.join(subfolder_path, latest_file)\n",
        "        checkpoint = torch.load(filepath, weights_only=True)\n",
        "\n",
        "        # Load the model state from the checkpoint\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        # If an optimizer is provided, load its state as well\n",
        "        if optimizer:\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "        # Try to load the associated JSON file if available\n",
        "        json_filepath = os.path.join(subfolder_path, latest_file.replace('.pth', '.json'))\n",
        "        json_data = None\n",
        "        if os.path.exists(json_filepath):\n",
        "            # If the JSON file exists, load its contents\n",
        "            with open(json_filepath, 'r') as json_file:\n",
        "                json_data = json.load(json_file)\n",
        "            print(\"Data loaded!\")\n",
        "        else:\n",
        "            # If no JSON file exists, print a message\n",
        "            print(\"No data found\")\n",
        "\n",
        "        # Print the epoch from which the model is resuming\n",
        "        print(f\"Checkpoint found: Resuming from epoch {checkpoint['epoch'] + 1}\\n\\n\")\n",
        "        return checkpoint['epoch'] + 1, json_data\n",
        "\n",
        "    # If no checkpoint is found, print a message and start from epoch 1\n",
        "    print(\"No checkpoint found, starting from epoch 1..\\n\\n\")\n",
        "    return 1, None  # Epoch starts from 1\n",
        "\n",
        "def delete_existing_checkpoints(subfolder=\"\"):\n",
        "    \"\"\"\n",
        "    Deletes all existing checkpoints in the specified subfolder.\n",
        "\n",
        "    Arguments:\n",
        "    subfolder -- Optional subfolder within the checkpoint directory to delete checkpoints from.\n",
        "    \"\"\"\n",
        "    subfolder_path = os.path.join(CHECKPOINT_DIR, subfolder)\n",
        "    if os.path.exists(subfolder_path):\n",
        "        for file_name in os.listdir(subfolder_path):\n",
        "            file_path = os.path.join(subfolder_path, file_name)\n",
        "            if os.path.isfile(file_path):\n",
        "                os.remove(file_path)\n",
        "        print(f\"All existing checkpoints in {subfolder_path} have been deleted.\")\n",
        "    else:\n",
        "        print(f\"No checkpoint folder found at {subfolder_path}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYCAlTArDfIP",
        "outputId": "dd43ce0f-6e2c-463a-b110-dffbfa5416a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 169M/169M [00:06<00:00, 26.1MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "#10% of the dataset kept for validation\n",
        "data_loader = CIFAR100DataLoader(batch_size=BATCH_SIZE, validation_split=0.1, download=True, num_workers=4, pin_memory=True)\n",
        "trainloader, validloader, testloader = data_loader.train_loader, data_loader.val_loader, data_loader.test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bWSl31M6DjPg"
      },
      "outputs": [],
      "source": [
        "global_model = LeNet5()\n",
        "criterion = nn.NLLLoss()# our loss function for classification tasks on CIFAR-100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZDhsA-A2DnC1"
      },
      "outputs": [],
      "source": [
        "from torch.backends import cudnn\n",
        "import time\n",
        "\n",
        "\n",
        "class Client:\n",
        "    def __init__(self, client_id, data_loader, model, device):\n",
        "        \"\"\"\n",
        "        Initializes a federated learning client.\n",
        "        :param client_id: Unique identifier for the client.\n",
        "        :param data_loader: Data loader specific to the client.\n",
        "        :param model: The model class to be used by the client.\n",
        "        :param device: The device (CPU/GPU) to perform computations.\n",
        "        \"\"\"\n",
        "        self.client_id = client_id\n",
        "        self.data_loader = data_loader\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "\n",
        "    def client_update(self, client_data, criterion, optimizer, local_steps=4, detailed_print=False):\n",
        "        \"\"\"\n",
        "        Trains a given client's local model on its dataset for a fixed number of steps (`local_steps`).\n",
        "\n",
        "        Args:\n",
        "            model (nn.Module): The local model to be updated.\n",
        "            client_id (int): Identifier for the client (used for logging/debugging purposes).\n",
        "            client_data (DataLoader): The data loader for the client's dataset.\n",
        "            criterion (Loss): The loss function used for training (e.g., CrossEntropyLoss).\n",
        "            optimizer (Optimizer): The optimizer used for updating model parameters (e.g., SGD).\n",
        "            local_steps (int): Number of local epochs to train on the client's dataset.\n",
        "            detailed_print (bool): If True, logs the final loss after training.\n",
        "\n",
        "        Returns:\n",
        "            dict: The state dictionary of the updated model.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        cudnn.benchmark  # Calling this optimizes runtime\n",
        "\n",
        "        self.model.train()  # Set the model to training mode\n",
        "        step_count = 0\n",
        "        total_loss = 0.0\n",
        "        correct_predictions = 0\n",
        "        total_samples = 0\n",
        "        while step_count < local_steps:\n",
        "            for data, targets in client_data:\n",
        "                # Move data and targets to the specified device (e.g., GPU or CPU)\n",
        "                data, targets = data.to(self.device), targets.to(self.device)\n",
        "\n",
        "\n",
        "                start_time = time.time()  # for testing-----------------------------\n",
        "\n",
        "                # Reset the gradients before backpropagation\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass: compute model predictions\n",
        "                outputs = self.model(data)\n",
        "\n",
        "                # Compute the loss\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "                # Backward pass: compute gradients and update weights\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                #---------- Accumulate metrics\n",
        "                #  Accumulates the weighted loss for the number of samples in the batch to account for any variation in\n",
        "                #  batch size due to, for example, the smaller final batch. A little too precise? :)\n",
        "                total_loss += loss.item() * data.size(0)\n",
        "                _, predicted = outputs.max(1)\n",
        "                correct_predictions += predicted.eq(targets).sum().item()\n",
        "                total_samples += data.size(0)\n",
        "\n",
        "                step_count +=1\n",
        "                if step_count >= local_steps:\n",
        "                  break\n",
        "\n",
        "        #---------- Compute averaged metrics\n",
        "        avg_loss = total_loss / total_samples\n",
        "        avg_accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "        # Optionally, print the loss for the last epoch of training\n",
        "        if detailed_print:\n",
        "          print(f'Client {self.client_id} --> Final Loss (Step {step_count}/{local_steps}): {loss.item()}')\n",
        "\n",
        "\n",
        "        # Return the updated model's state dictionary (weights)\n",
        "        return self.model.state_dict(), avg_loss, avg_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CSdo3O9eoBFv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DIR = '/content/drive/MyDrive/colab_plots/'\n",
        "\n",
        "def plot_client_selection(client_selection_count, file_name):\n",
        "    \"\"\"\n",
        "    Bar plot to visualize the frequency of client selections in a federated learning simulation.\n",
        "\n",
        "    Args:\n",
        "        client_selection_count (list): list containing the number of times each client was selected.\n",
        "        file_name (str): name of the file to save the plot.\n",
        "    \"\"\"\n",
        "    # Fixed base directory\n",
        "    directory = DIR +  'plots_federated/'\n",
        "    # Ensure the base directory exists\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "    # Complete path for the file\n",
        "    file_path = os.path.join(directory, file_name)\n",
        "\n",
        "    num_clients = len(client_selection_count)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(range(num_clients), client_selection_count, alpha=0.7, edgecolor='black')\n",
        "    plt.xlabel(\"Client ID\", fontsize=14)\n",
        "    plt.ylabel(\"Selection Count\", fontsize=14)\n",
        "    plt.title(\"Client Selection Frequency\", fontsize=16)\n",
        "    plt.xticks(range(num_clients), fontsize=10, rotation=90 if num_clients > 20 else 0)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(file_path, format=\"png\", dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "def test(global_model, test_loader):\n",
        "    \"\"\"\n",
        "    Evaluate the global model on the test dataset.\n",
        "\n",
        "    Args:\n",
        "        global_model (nn.Module): The global model to be evaluated.\n",
        "        test_loader (DataLoader): DataLoader for the test dataset.\n",
        "\n",
        "    Returns:\n",
        "        float: The accuracy of the model on the test dataset.\n",
        "    \"\"\"\n",
        "    test_accuracy, _ = evaluate(global_model, test_loader)\n",
        "    return test_accuracy\n",
        "\n",
        "def plot_metrics(train_accuracies, train_losses, val_accuracies,val_losses, file_name):\n",
        "    \"\"\"\n",
        "    Plot the training and validation metrics for a federated learning simulation.\n",
        "\n",
        "    Args:\n",
        "        train_accuracies (list): List of training accuracies.\n",
        "        train_losses (list): List of training losses.\n",
        "        val_accuracies (list): List of validation accuracies.\n",
        "        val_losses (list): List of validation losses.\n",
        "        file_name (str): Name of the file to save the plot.\n",
        "    \"\"\"\n",
        "    # Fixed base directory\n",
        "    directory = DIR + '/plots_federated/'\n",
        "    # Ensure the base directory exists\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "    # Complete path for the file\n",
        "    file_path = os.path.join(directory, file_name)\n",
        "\n",
        "    # Create a list of epochs for the x-axis\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot the training and validation losses\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, train_losses, label='Train Loss', color='blue')\n",
        "    plt.plot(epochs, val_losses, label='Validation Loss', color='red')\n",
        "    plt.xlabel('Rounds', fontsize=14)\n",
        "    plt.ylabel('Loss', fontsize=14)\n",
        "    plt.title('Training and Validation Loss', fontsize=16)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(file_path.replace('.png', '_loss.png'), format='png', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # Plot the training and validation accuracies\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, train_accuracies, label='Train Accuracy', color='blue')\n",
        "    plt.plot(epochs, val_accuracies, label='Validation Accuracy', color='red')\n",
        "    plt.xlabel('Rounds', fontsize=14)\n",
        "    plt.ylabel('Accuracy', fontsize=14)\n",
        "    plt.title('Training and Validation Accuracy', fontsize=16)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(file_path.replace('.png', '_accuracy.png'), format='png', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def save_data(global_model, val_accuracies, val_losses, train_accuracies, train_losses,client_count, file_name):\n",
        "    \"\"\"\n",
        "    Save the global model, val_accuracies, val_losses, train_accuracies,train_losses and client_count to a file.\n",
        "\n",
        "    Args:\n",
        "        global_model (nn.Module): The global model to be saved.\n",
        "        val_accuracies (list): List of validation accuracies.\n",
        "        val_losses (list): List of validation losses.\n",
        "        train_accuracies (list): List of training accuracies.\n",
        "        train_losses (list): List of training losses.\n",
        "        file_name (str): Name of the file to save the data.\n",
        "    \"\"\"\n",
        "    # Fixed base directory\n",
        "    directory = DIR + '/trained_models/'\n",
        "    # Ensure the base directory exists\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "    # Complete path for the file\n",
        "    file_path = os.path.join(directory, file_name)\n",
        "\n",
        "    # Save all data (model state and metrics) into a dictionary\n",
        "    save_dict = {\n",
        "        'model_state': global_model.state_dict(),\n",
        "        'val_accuracies': val_accuracies,\n",
        "        'val_losses': val_losses,\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'train_losses': train_losses,\n",
        "        'client_count': client_count\n",
        "    }\n",
        "\n",
        "    # Save the dictionary to the specified file\n",
        "    torch.save(save_dict, file_path)\n",
        "    print(f\"Data saved successfully to {file_path}\")\n",
        "\n",
        "def load_data(model, file_name):\n",
        "    \"\"\"\n",
        "    Load the model weights and metrics from a file.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The model to load the weights into.\n",
        "        file_name (str): Name of the file to load the data from.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the model, val_accuracies, val_losses, train_accuracies train_losses and client_count.\n",
        "    \"\"\"\n",
        "    # Fixed base directory\n",
        "    directory = DIR+ 'trained_models/'\n",
        "    # Complete path for the file\n",
        "    file_path = os.path.join(directory, file_name)\n",
        "\n",
        "    # Load the saved data from the specified file\n",
        "    save_dict = torch.load(file_path)\n",
        "\n",
        "    # Load the model state\n",
        "    model.load_state_dict(save_dict['model_state'])\n",
        "\n",
        "    # Extract the metrics\n",
        "    val_accuracies = save_dict['val_accuracies']\n",
        "    val_losses = save_dict['val_losses']\n",
        "    train_accuracies = save_dict['train_accuracies']\n",
        "    train_losses = save_dict['train_losses']\n",
        "    client_count = save_dict['client_count']\n",
        "\n",
        "    print(f\"Data loaded successfully from {file_path}\")\n",
        "\n",
        "    return model, val_accuracies, val_losses, train_accuracies, train_losses,client_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2mU8_ccaD6Mu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "from torch.utils.data import Subset\n",
        "import os\n",
        "import random\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import logging\n",
        "\n",
        "log = logging.getLogger(__name__)\n",
        "\n",
        "class Server:\n",
        "    def __init__(self, global_model, device, CHECKPOINT_DIR):\n",
        "        self.global_model = global_model\n",
        "        self.device = device\n",
        "        self.CHECKPOINT_DIR = CHECKPOINT_DIR\n",
        "        # Ensure the checkpoint directory exists, creating it if necessary\n",
        "        os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "    def fedavg_aggregate(self, client_states, client_sizes, client_avg_losses, client_avg_accuracies):\n",
        "        \"\"\"\n",
        "        Aggregates model updates and client metrics from selected clients using the Federated Averaging (FedAvg) algorithm.\n",
        "        The updates and metrics are weighted by the size of each client's dataset.\n",
        "\n",
        "        Args:\n",
        "            global_model (nn.Module): The global model whose structure is used for aggregation.\n",
        "            client_states (list[dict]): A list of state dictionaries (model weights) from participating clients.\n",
        "            client_sizes (list[int]): A list of dataset sizes for the participating clients.\n",
        "            client_avg_losses (list[float]): A list of average losses for the participating clients.\n",
        "            client_avg_accuracies (list[float]): A list of average accuracies for the participating clients.\n",
        "\n",
        "        Returns:\n",
        "            tuple: The aggregated state dictionary with updated model parameters, global average loss, and global average accuracy.\n",
        "        \"\"\"\n",
        "        # Copy the global model's state dictionary for aggregation\n",
        "        new_state = deepcopy(self.global_model.state_dict())\n",
        "\n",
        "        # Calculate the total number of samples across all participating clients\n",
        "        total_samples = sum(client_sizes)\n",
        "\n",
        "        # Initialize all parameters in the new state to zero\n",
        "        for key in new_state:\n",
        "            new_state[key] = torch.zeros_like(new_state[key])\n",
        "\n",
        "        # Initialize metrics\n",
        "        total_loss = 0.0\n",
        "        total_accuracy = 0.0\n",
        "\n",
        "        # Perform a weighted average of client updates and metrics\n",
        "        for state, size, avg_loss, avg_accuracy in zip(client_states, client_sizes, client_avg_losses, client_avg_accuracies):\n",
        "            for key in new_state:\n",
        "                # Add the weighted contribution of each client's parameters\n",
        "                new_state[key] += (state[key] * size / total_samples)\n",
        "            total_loss += avg_loss * size\n",
        "            total_accuracy += avg_accuracy * size\n",
        "\n",
        "        # Calculate global metrics\n",
        "        global_avg_loss = total_loss / total_samples\n",
        "        global_avg_accuracy = total_accuracy / total_samples\n",
        "\n",
        "        # Return the aggregated state dictionary with updated weights and global metrics\n",
        "        return new_state, global_avg_loss, global_avg_accuracy\n",
        "\n",
        "\n",
        "    # Federated Learning Training Loop\n",
        "    def train_federated(self, criterion, trainloader, validloader, num_clients, num_classes, rounds, lr, momentum, batchsize, wd, C=0.1, local_steps=4, log_freq=10, detailed_print=False,gamma=None):\n",
        "        val_accuracies = []\n",
        "        val_losses = []\n",
        "        train_accuracies = []\n",
        "        train_losses = []\n",
        "        best_model_state = None  # The model with the best accuracy\n",
        "        client_selection_count = [0] * num_clients #Count how many times a client has been selected\n",
        "        best_val_acc = 0.0\n",
        "\n",
        "        shards = self.sharding(trainloader.dataset, num_clients, num_classes) #each shard represent the training data for one client\n",
        "        client_sizes = [len(shard) for shard in shards]\n",
        "\n",
        "        self.global_model.to(self.device) #as alwayse, we move the global model to the specified device (CPU or GPU)\n",
        "\n",
        "        #loading checkpoint if it exists\n",
        "        checkpoint_start_step, data_to_load = load_checkpoint(model=self.global_model,optimizer=None,hyperparameters=f\"LR{lr}_WD{wd}\", subfolder=\"Federated/\")\n",
        "        if data_to_load is not None:\n",
        "          val_accuracies = data_to_load['val_accuracies']\n",
        "          val_losses = data_to_load['val_losses']\n",
        "          train_accuracies = data_to_load['train_accuracies']\n",
        "          train_losses = data_to_load['train_losses']\n",
        "          client_selection_count = data_to_load['client_selection_count']\n",
        "        probabilities = None\n",
        "        if gamma is not None:\n",
        "            probabilities = self.skewed_probabilities(num_clients, gamma)\n",
        "\n",
        "        # ********************* HOW IT WORKS ***************************************\n",
        "        # The training runs for rounds iterations (GLOBAL_ROUNDS=2000)\n",
        "        # Each round simulates one communication step in federated learning, including:\n",
        "        # 1) client selection\n",
        "        # 2) local training (of each client)\n",
        "        # 3) central aggregation\n",
        "        for round_num in range(checkpoint_start_step, rounds):\n",
        "            if (round_num+1) % log_freq == 0 and detailed_print:\n",
        "              print(f\"------------------------------------- Round {round_num+1} ------------------------------------------------\" )\n",
        "\n",
        "            # 1) client selection: In each round, a fraction C (e.g., 10%) of clients is randomly selected to participate.\n",
        "            #     This reduces computation costs and mimics real-world scenarios where not all devices are active.\n",
        "            selected_clients = self.client_selection(num_clients, C,probabilities)\n",
        "            client_states = []\n",
        "            client_avg_losses = []\n",
        "            client_avg_accuracies = []\n",
        "            for client_id in selected_clients:\n",
        "                client_selection_count[client_id] += 1\n",
        "\n",
        "            # 2) local training: for each client updates the model using the client's data for local_steps epochs\n",
        "            for client_id in selected_clients:\n",
        "                local_model = deepcopy(self.global_model) #it creates a local copy of the global model\n",
        "                optimizer = optim.SGD(local_model.parameters(), lr=lr, momentum=momentum, weight_decay=wd) #same of the centralized version\n",
        "                client_loader = DataLoader(shards[client_id], batch_size=batchsize, shuffle=True)\n",
        "\n",
        "                print_log =  (round_num+1) % log_freq == 0 and detailed_print\n",
        "                client = Client(client_id, client_loader, local_model, self.device)\n",
        "                client_local_state, client_avg_loss, client_avg_accuracy  = client.client_update(client_loader, criterion, optimizer, local_steps, print_log)\n",
        "\n",
        "                client_states.append(client_local_state)\n",
        "                client_avg_losses.append(client_avg_loss)\n",
        "                client_avg_accuracies.append(client_avg_accuracy)\n",
        "\n",
        "\n",
        "            # 3) central aggregation: aggregates participating client updates using fedavg_aggregate\n",
        "            #    and replaces the current parameters of global_model with the returned ones.\n",
        "            aggregated_state, train_loss, train_accuracy = self.fedavg_aggregate(client_states, [client_sizes[i] for i in selected_clients], client_avg_losses, client_avg_accuracies)\n",
        "        \n",
        "            self.global_model.load_state_dict(aggregated_state)\n",
        "\n",
        "            train_accuracies.append(train_accuracy)\n",
        "            train_losses.append(train_loss)\n",
        "            #Validation at the server\n",
        "            val_accuracy, val_loss = evaluate(self.global_model, validloader)\n",
        "            val_accuracies.append(val_accuracy)\n",
        "            val_losses.append(val_loss)\n",
        "            if val_accuracy > best_val_acc:\n",
        "                best_val_acc = val_accuracy\n",
        "                best_model_state = deepcopy(self.global_model.state_dict())\n",
        "\n",
        "            if (round_num+1) % log_freq == 0:\n",
        "                if detailed_print:\n",
        "                    print(f\"--> best validation accuracy: {best_val_acc:.2f}\\n--> training accuracy: {train_accuracy:.2f}\")\n",
        "                    print(f\"--> validation loss: {val_loss:.4f}\\n--> training loss: {train_loss:.4f}\")\n",
        "\n",
        "                # checkpointing\n",
        "                checkpoint_data = {\n",
        "                    'val_accuracies': val_accuracies,\n",
        "                    'val_losses': val_losses,\n",
        "                    'train_accuracies': train_accuracies,\n",
        "                    'train_losses': train_losses,\n",
        "                    'client_selection_count': client_selection_count\n",
        "                }\n",
        "                save_checkpoint(self.global_model,optimizer=None, epoch=round_num, hyperparameters=f\"LR{lr}_WD{wd}\", subfolder=\"Federated/\", checkpoint_data=checkpoint_data)\n",
        "                if detailed_print:\n",
        "                    print(f\"------------------------------ Round {round_num+1} terminated: model updated -----------------------------\\n\\n\" )\n",
        "\n",
        "        self.global_model.load_state_dict(best_model_state)\n",
        "\n",
        "        return self.global_model, val_accuracies, val_losses, train_accuracies, train_losses, client_selection_count\n",
        "\n",
        "    def skewed_probabilities(self, number_of_clients, gamma=0.5):\n",
        "            # Generate skewed probabilities using a Dirichlet distribution\n",
        "            probabilities = np.random.dirichlet(np.ones(number_of_clients) * gamma)\n",
        "            return probabilities\n",
        "\n",
        "    def client_selection(self,number_of_clients, clients_fraction, probabilities=None):\n",
        "        \"\"\"\n",
        "        Selects a subset of clients based on uniform or skewed distribution.\n",
        "        \n",
        "        Args:\n",
        "        number_of_clients (int): Total number of clients.\n",
        "        clients_fraction (float): Fraction of clients to be selected.\n",
        "        uniform (bool): If True, selects clients uniformly. If False, selects clients based on a skewed distribution.\n",
        "        gamma (float): Hyperparameter for the Dirichlet distribution controlling the skewness (only used if uniform=False).\n",
        "        \n",
        "        Returns:\n",
        "        list: List of selected client indices.\n",
        "        \"\"\"\n",
        "        num_clients_to_select = int(number_of_clients * clients_fraction)\n",
        "        \n",
        "        if probabilities is None:\n",
        "            # Uniformly select clients without replacement\n",
        "            selected_clients = np.random.choice(number_of_clients, num_clients_to_select, replace=False)\n",
        "        else:\n",
        "            selected_clients = np.random.choice(number_of_clients, num_clients_to_select, replace=False, p=probabilities)\n",
        "        \n",
        "        return selected_clients\n",
        "\n",
        "\n",
        "\n",
        "    def sharding(self, dataset, number_of_clients, number_of_classes=100):\n",
        "        \"\"\"\n",
        "        Function that performs the sharding of the dataset given as input.\n",
        "        dataset: dataset to be split (should be a PyTorch dataset or similar);\n",
        "        number_of_clients: the number of partitions we want to obtain (e.g., 100 for 100 clients);\n",
        "        number_of_classes: (int) the number of classes inside each partition, or 100 for IID (default to 100).\n",
        "        \"\"\"\n",
        "\n",
        "        # Validate the number of classes input\n",
        "        if not (1 <= number_of_classes <= 100):\n",
        "            raise ValueError(\"number_of_classes should be an integer between 1 and 100\")\n",
        "\n",
        "        # Get labels for sorting\n",
        "        labels = np.array([dataset[i][1] for i in range(len(dataset))]) \n",
        "        TOTAL_NUM_CLASSES = len(set(labels))\n",
        "\n",
        "        shard_size = len(dataset) // (number_of_clients * number_of_classes)  # Shard size for each class per client\n",
        "        #print(\"dataset len: \", len(dataset), \", shard size: \", shard_size, \", number of shards: \",(number_of_clients * number_of_classes))\n",
        "        if shard_size == 0:\n",
        "            raise ValueError(\"Shard size is too small; increase dataset size or reduce number of clients/classes.\")\n",
        "\n",
        "\n",
        "        # Divide the dataset into shards, each containing samples from one class\n",
        "        shards = {}\n",
        "        for i in range(TOTAL_NUM_CLASSES):  \n",
        "            # Filter samples for the current class\n",
        "            class_samples = [j for j in range(len(labels)) if labels[j] == i]\n",
        "            shards_of_class_i = []\n",
        "            # While there are enough samples to form a shard\n",
        "            while len(class_samples) >= shard_size and len(shards_of_class_i) < number_of_clients*(number_of_classes/number_of_clients):\n",
        "                # Take a shard of shard_size samples\n",
        "                shards_of_class_i.append(class_samples[:shard_size])\n",
        "                # Remove the shard_size samples from class_samples\n",
        "                class_samples = class_samples[shard_size:]\n",
        "            # Add the last shard (which might be smaller than shard_size)\n",
        "            if len(class_samples) > 0 and len(shards_of_class_i) == number_of_clients*(number_of_classes/number_of_clients):\n",
        "                # Distribute remaining samples among existing shards\n",
        "                for sample in class_samples:\n",
        "                    random_shard = random.choice(shards_of_class_i)\n",
        "                    random_shard.append(sample)\n",
        "            elif class_samples:\n",
        "                shards_of_class_i.append(class_samples)\n",
        "            # Store the class shards\n",
        "            shards[i] = shards_of_class_i  # Store shards by class\n",
        "        \n",
        "        client_shards = []  # List to store the dataset for each client          \n",
        "        for client_id in range(number_of_clients):\n",
        "                \n",
        "            client_labels = [label % TOTAL_NUM_CLASSES for label in range(client_id, client_id + number_of_classes)]\n",
        "            #print(client_labels)\n",
        "\n",
        "            # Collect the shards for the selected classes\n",
        "            client_shard_indices = []\n",
        "            for label in client_labels:\n",
        "                shard = shards[label].pop(0)  # Pop the first shard from the class's shard list\n",
        "                client_shard_indices.append(shard)\n",
        "\n",
        "            # Flatten and combine the shard indices into one list\n",
        "            client_indices = [idx for shard in client_shard_indices for idx in shard]\n",
        "\n",
        "            #print(f\"Client {client_id} has {len(client_indices)} samples divided in {len(client_shard_indices)} shards (classes).\")\n",
        "            # Create a Subset for the client\n",
        "            client_dataset = Subset(dataset, client_indices)\n",
        "            client_shards.append(client_dataset)\n",
        "        \n",
        "        return client_shards  # Return the list of dataset subsets (shards) for each client\n",
        "        \n",
        "    def plot_sharding_data_distribution(self, trainloader, num_clients, num_classes):\n",
        "        shards = self.sharding(trainloader.dataset, num_clients, num_classes)\n",
        "        for client_id in range(num_clients):\n",
        "            client_dataset = shards[client_id]\n",
        "            #print(f\"Client {client_id} has {len(client_dataset)} samples.\")\n",
        "            plot_local_data_distribution(client_dataset,f\"Nc{num_classes}\", f\"DataDistribution_client{client_id}.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qNFG9tNdo05C",
        "outputId": "1e55f9a1-7109-4ec5-8686-2d963ef99f29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameter tuning for num_classes=1, local_steps=4\n",
            "Learning rate: 0.1, Weight decay: 0.01\n",
            "No checkpoint found, starting from epoch 1.\n",
            "Checkpoint saved: /content/drive/MyDrive/colab_checkpoints/Federated/model_epoch_99_params_LR0.1_WD0.01.pth\n",
            "Validation accuracy: 1.7000000000000002 with lr: 0.1 and wd: 0.01\n",
            "Learning rate: 0.1, Weight decay: 0.001\n",
            "No checkpoint found, starting from epoch 1..\n",
            "\n",
            "\n",
            "Checkpoint saved: /content/drive/MyDrive/colab_checkpoints/Federated/model_epoch_99_params_LR0.1_WD0.001.pth\n",
            "Validation accuracy: 1.06 with lr: 0.1 and wd: 0.001\n",
            "Learning rate: 0.1, Weight decay: 0.0001\n",
            "No checkpoint found, starting from epoch 1..\n",
            "\n",
            "\n",
            "Checkpoint saved: /content/drive/MyDrive/colab_checkpoints/Federated/model_epoch_99_params_LR0.1_WD0.0001.pth\n",
            "Validation accuracy: 1.02 with lr: 0.1 and wd: 0.0001\n",
            "Learning rate: 0.01, Weight decay: 0.01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-13-6cd4c7b72d7f>\", line 23, in <cell line: 23>\n",
            "    hyperparameters_tuning(1,4,100) #Nc = 1, J=4\n",
            "  File \"<ipython-input-13-6cd4c7b72d7f>\", line 13, in hyperparameters_tuning\n",
            "    global_model, val_accuracies, val_losses, train_accuracies, train_losses, client_selection_count = server.train_federated(criterion, trainloader, validloader, num_clients=NUM_CLIENTS, num_classes=num_classes, rounds=rounds, lr=lr, momentum=MOMENTUM, batchsize=BATCH_SIZE, wd=wd, C=FRACTION_CLIENTS, local_steps=local_steps,log_freq=100, detailed_print=False,gamma=None)\n",
            "  File \"<ipython-input-12-dfccb30bb935>\", line 75, in train_federated\n",
            "    shards = self.sharding(trainloader.dataset, num_clients, num_classes) #each shard represent the training data for one client\n",
            "  File \"<ipython-input-12-dfccb30bb935>\", line 226, in sharding\n",
            "    labels = np.array([dataset[i][1] for i in range(len(dataset))])\n",
            "  File \"<ipython-input-12-dfccb30bb935>\", line 226, in <listcomp>\n",
            "    labels = np.array([dataset[i][1] for i in range(len(dataset))])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\", line 412, in __getitem__\n",
            "    return self.dataset[self.indices[idx]]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/datasets/cifar.py\", line 119, in __getitem__\n",
            "    img = self.transform(img)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n",
            "    img = t(img)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\", line 669, in forward\n",
            "    img = F.pad(img, self.padding, self.fill, self.padding_mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\", line 526, in pad\n",
            "    return F_pil.pad(img, padding=padding, fill=fill, padding_mode=padding_mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\", line 143, in pad\n",
            "    @torch.jit.unused\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 869, in getmodule\n",
            "    if ismodule(module) and hasattr(module, '__file__'):\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-6cd4c7b72d7f>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mhyperparameters_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Nc = 1, J=4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m#hyperparameters_tuning(1,8,50) Nc = 1, J=8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-6cd4c7b72d7f>\u001b[0m in \u001b[0;36mhyperparameters_tuning\u001b[0;34m(num_classes, local_steps, rounds)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mserver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mServer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHECKPOINT_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mglobal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_selection_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_federated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_clients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_CLIENTS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMOMENTUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFRACTION_CLIENTS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetailed_print\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mplot_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"FederatedTuning_Nc_{num_classes}_J_{local_steps}_lr_{lr}_wd_{wd}.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-dfccb30bb935>\u001b[0m in \u001b[0;36mtrain_federated\u001b[0;34m(self, criterion, trainloader, validloader, num_clients, num_classes, rounds, lr, momentum, batchsize, wd, C, local_steps, log_freq, detailed_print, gamma)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mshards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msharding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_clients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#each shard represent the training data for one client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mclient_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshard\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshards\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-dfccb30bb935>\u001b[0m in \u001b[0;36msharding\u001b[0;34m(self, dataset, number_of_clients, number_of_classes)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;31m# Extract labels from the dataset (assuming each sample is a tuple (data, label))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mTOTAL_NUM_CLASSES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Determine the total number of unique classes in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-dfccb30bb935>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;31m# Extract labels from the dataset (assuming each sample is a tuple (data, label))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mTOTAL_NUM_CLASSES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Determine the total number of unique classes in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(img, padding, fill, padding_mode)\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(img, padding, fill, padding_mode)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munused\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m def pad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "#Hyperparameters tuning function\n",
        "def hyperparameters_tuning(num_classes, local_steps, rounds):\n",
        "    print(f\"Hyperparameter tuning for num_classes={num_classes}, local_steps={local_steps}\")\n",
        "    lr_values = [0.1,0.05,0.01,0.005,0.001,0.0005,0.0001]\n",
        "    wd_values = [0.001,0.0001]\n",
        "    best_val_accuracy = 0\n",
        "    best_setting = None\n",
        "    for lr in lr_values:\n",
        "        for wd in wd_values:\n",
        "            print(f\"Learning rate: {lr}, Weight decay: {wd}\")\n",
        "            global_model = LeNet5()\n",
        "            server = Server(global_model, DEVICE, CHECKPOINT_DIR)\n",
        "            global_model, val_accuracies, val_losses, train_accuracies, train_losses, client_selection_count = server.train_federated(criterion, trainloader, validloader, num_clients=NUM_CLIENTS, num_classes=num_classes, rounds=rounds, lr=lr, momentum=MOMENTUM, batchsize=BATCH_SIZE, wd=wd, C=FRACTION_CLIENTS, local_steps=local_steps,log_freq=100, detailed_print=False,gamma=None)\n",
        "            plot_metrics(train_accuracies, train_losses,val_accuracies, val_losses, f\"FederatedTuning_Nc_{num_classes}_J_{local_steps}_lr_{lr}_wd_{wd}.png\")\n",
        "            print(f\"Validation accuracy: {max(val_accuracies)} with lr: {lr} and wd: {wd}\")\n",
        "            avg_val_accuracy = sum(val_accuracies) / len(val_accuracies)\n",
        "            if avg_val_accuracy > best_val_accuracy:\n",
        "                best_val_accuracy = avg_val_accuracy\n",
        "                best_setting = (lr, wd)\n",
        "    print(f\"Best setting: {best_setting} with validation accuracy: {best_val_accuracy}\")\n",
        "    return best_setting\n",
        "\n",
        "hyperparameters_tuning(1,4,100) #Nc = 1, J=4\n",
        "#hyperparameters_tuning(1,8,50) Nc = 1, J=8\n",
        "#hyperparameters_tuning(1,16,25) Nc = 1, J=8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uz2DgN57pEzi"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "LOCAL_STEPS_VALUES = [4, 8, 16]  # Values for J (number of local steps)\n",
        "NUM_CLASSES_VALUES = [1, 5, 10, 50]  # Number of classes per client for Non-IID\n",
        "NUM_RUNDS = {4: 2000, 8: 1000, 16:500}\n",
        "IID_CLASSES = 100  # Full IID distribution\n",
        "\n",
        "# Function to perform the training and testing for a given configuration\n",
        "def run_experiment(num_classes, local_steps, plot_suffix):\n",
        "    print(f\"Running experiment: num_classes={num_classes}, local_steps={local_steps}\")\n",
        "    global_model = LeNet5()\n",
        "    server = Server(global_model, DEVICE, CHECKPOINT_DIR)\n",
        "\n",
        "    tuning_rounds = int(NUM_RUNDS[local_steps]/20)\n",
        "    #best_lr, best_wd = to be manually set\n",
        "\n",
        "    global_model, val_accuracies, val_losses, train_accuracies, train_losses, client_selection_count = server.train_federated(\n",
        "        criterion, trainloader, validloader,\n",
        "        num_clients=NUM_CLIENTS, num_classes=num_classes,\n",
        "        rounds=NUM_RUNDS[local_steps], lr=best_lr, momentum=MOMENTUM,\n",
        "        batchsize=BATCH_SIZE, wd=best_wd, C=FRACTION_CLIENTS,\n",
        "        local_steps=local_steps, log_freq=100,\n",
        "        detailed_print=False, gamma=None  # No skewed sampling for this experiment\n",
        "    )\n",
        "\n",
        "    # Testing and plotting\n",
        "    test_accuracy = test(global_model, testloader)\n",
        "    plot_metrics(train_accuracies, train_losses, val_accuracies, val_losses, f\"Federated_{plot_suffix}_LR_{best_lr}_WD_{best_wd}.png\")\n",
        "    print(f\"Test accuracy for num_classes={num_classes}, local_steps={local_steps}: {test_accuracy}\")\n",
        "\n",
        "    # Save data for future analysis\n",
        "    save_data(global_model, val_accuracies, val_losses, train_accuracies, train_losses, client_selection_count, f\"Federated_{plot_suffix}_LR_{best_lr}_WD_{best_wd}.pth\")\n",
        "num_classes = 1\n",
        "local_steps = 4 #8 and 16\n",
        "plot_suffix = f\"num_classes_{num_classes}_local_steps_{local_steps}\"\n",
        "run_experiment(num_classes, local_steps, plot_suffix)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
