{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usjY0Bcpq_KW"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6AYtngaiB0cJ"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from google.colab import drive\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import io\n",
        "import json\n",
        "from google.colab import files\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.backends import cudnn\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "import torch.optim as optim\n",
        "from copy import deepcopy\n",
        "import logging\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ip3R30psZxR"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjnl6b5eDPMY",
        "outputId": "99a350d5-8800-462d-d8ec-1424eddc7c19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Constants for FL training\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(DEVICE)\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "NUM_CLIENTS = 1129  # Total number of clients in the federation\n",
        "FRACTION_CLIENTS = 0.1  # Fraction of clients selected per round (C)\n",
        "LOCAL_STEPS = 100  # Number of local steps (J)\n",
        "GLOBAL_ROUNDS = 2000  # Total number of communication rounds\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "criterion =  nn.CrossEntropyLoss()\n",
        "\n",
        "BATCH_SIZE = 100  # Batch size for local training\n",
        "MOMENTUM = 0.0  # Momentum for SGD optimizer\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/colab_checkpoints/'\n",
        "LOG_FREQUENCY = 10 # Frequency of logging training progress"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5MUotYescdQ"
      },
      "source": [
        "## Remove any existing checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7l_1QspQNQS-"
      },
      "outputs": [],
      "source": [
        "!rm -r {CHECKPOINT_DIR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sO2Vy3ksgs8"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eNOz0NNeDaX6"
      },
      "outputs": [],
      "source": [
        "class CharLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    Character-level LSTM model for text processing tasks.\n",
        "    Includes embedding, LSTM, and a fully connected output layer.\n",
        "    We use:\n",
        "    - embedding size equal to 8;\n",
        "    - 2 LSTM layers, each with 256 nodes;\n",
        "    - densely connected softmax output layer.\n",
        "\n",
        "    We can avoid to use explicitly the softmax function in the model and\n",
        "    keep a cross entropy loss function as a loss function.\n",
        "\n",
        "    as mentioned in paper [2] (Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush,\n",
        "    Jakub Konečný, Sanjiv Kumar, H. Brendan McMahan; Adaptive Federated Optimization, 2021)\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size = 70, embedding_size = 8, lstm_hidden_dim = 256, seq_length=80):\n",
        "        super(CharLSTM, self).__init__()\n",
        "        self.seq_length = seq_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.lstm_hidden_dim = lstm_hidden_dim\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_size)\n",
        "        self.lstm1 = nn.LSTM(input_size=embedding_size, hidden_size=lstm_hidden_dim, batch_first=True)\n",
        "        self.lstm2 = nn.LSTM(input_size=lstm_hidden_dim, hidden_size=lstm_hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(lstm_hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Forward pass through the model.\n",
        "        \"\"\"\n",
        "        # Layer 1: Embedding\n",
        "        x = self.embedding(x)  # Output shape: (batch_size, seq_length, embedding_dim)\n",
        "\n",
        "        # Layer 2: First LSTM\n",
        "        x, _ = self.lstm1(x)  # Output shape: (batch_size, seq_length, lstm_hidden_dim)\n",
        "\n",
        "        # Layer 3: Second LSTM\n",
        "        x, hidden = self.lstm2(x)  # Output shape: (batch_size, seq_length, lstm_hidden_dim)\n",
        "\n",
        "        # Layer 4: Fully Connected Layer\n",
        "        x = self.fc(x)  # Output shape: (batch_size, seq_length, vocab_size)\n",
        "\n",
        "        # Softmax Activation\n",
        "        #x = self.softmax(x)  # Output shape: (batch_size, seq_length, vocab_size)\n",
        "        return x[:, -1, :], hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        \"\"\"Initializes hidden and cell states for the LSTM.\"\"\"\n",
        "        return (torch.zeros(2, batch_size, self.lstm_hidden_dim),\n",
        "            torch.zeros(2, batch_size, self.lstm_hidden_dim))\n",
        "        #2 is equal to the number of lstm layers!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glw8yLjosjzN"
      },
      "source": [
        "# Checkpointing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sfb3t6fREwje"
      },
      "outputs": [],
      "source": [
        "# Ensure the checkpoint directory exists, creating it if necessary\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, hyperparameters, subfolder=\"\", checkpoint_data=None):\n",
        "    \"\"\"\n",
        "    Saves the model checkpoint and removes the previous one if it exists.\n",
        "\n",
        "    Arguments:\n",
        "    model -- The model whose state is to be saved.\n",
        "    optimizer -- The optimizer whose state is to be saved (can be None).\n",
        "    epoch -- The current epoch of the training process.\n",
        "    hyperparameters -- A string representing the model's hyperparameters for file naming.\n",
        "    subfolder -- Optional subfolder within the checkpoint directory to save the checkpoint.\n",
        "    checkpoint_data -- Data to save in a JSON file (e.g., training logs).\n",
        "    \"\"\"\n",
        "    # Define the path for the subfolder where checkpoints will be stored\n",
        "    subfolder_path = os.path.join(CHECKPOINT_DIR, subfolder)\n",
        "    # Create the subfolder if it doesn't exist\n",
        "    os.makedirs(subfolder_path, exist_ok=True)\n",
        "\n",
        "    # Construct filenames for both the model checkpoint and the associated JSON file\n",
        "    filename = f\"model_epoch_{epoch}_params_{hyperparameters}.pth\"\n",
        "    filepath = os.path.join(subfolder_path, filename)\n",
        "    filename_json = f\"model_epoch_{epoch}_params_{hyperparameters}.json\"\n",
        "    filepath_json = os.path.join(subfolder_path, filename_json)\n",
        "\n",
        "    # Define the filenames for the previous checkpoint files, to remove them if necessary\n",
        "    previous_filepath = os.path.join(subfolder_path, f\"model_epoch_{epoch - 1}_params_{hyperparameters}.pth\")\n",
        "    previous_filepath_json = os.path.join(subfolder_path, f\"model_epoch_{epoch - 1}_params_{hyperparameters}.json\")\n",
        "\n",
        "    # Remove the previous checkpoint if it exists, but only for epochs greater than 1\n",
        "    if epoch > 1 and os.path.exists(previous_filepath):\n",
        "        os.remove(previous_filepath)\n",
        "        os.remove(previous_filepath_json)\n",
        "\n",
        "    # Prepare the checkpoint data dictionary\n",
        "    checkpoint = {'model_state_dict': model.state_dict(), 'epoch': epoch}\n",
        "    # If an optimizer is provided, save its state as well\n",
        "    if optimizer is not None:\n",
        "        checkpoint['optimizer_state_dict'] = optimizer.state_dict()\n",
        "\n",
        "    # Save the model and optimizer (if provided) state dictionary to the checkpoint file\n",
        "    torch.save(checkpoint, filepath)\n",
        "    print(f\"Checkpoint saved: {filepath}\")\n",
        "\n",
        "    # If additional data (e.g., training logs) is provided, save it to a JSON file\n",
        "    if checkpoint_data:\n",
        "        with open(filepath_json, 'w') as json_file:\n",
        "            json.dump(checkpoint_data, json_file, indent=4)\n",
        "\n",
        "def load_checkpoint(model, optimizer, hyperparameters, subfolder=\"\"):\n",
        "    \"\"\"\n",
        "    Loads the latest checkpoint available based on the specified hyperparameters.\n",
        "\n",
        "    Arguments:\n",
        "    model -- The model whose state will be updated from the checkpoint.\n",
        "    optimizer -- The optimizer whose state will be updated from the checkpoint (can be None).\n",
        "    hyperparameters -- A string representing the model's hyperparameters for file naming.\n",
        "    subfolder -- Optional subfolder within the checkpoint directory to look for checkpoints.\n",
        "\n",
        "    Returns:\n",
        "    The next epoch to resume from and the associated JSON data if available.\n",
        "    \"\"\"\n",
        "    # Define the path to the subfolder where checkpoints are stored\n",
        "    subfolder_path = os.path.join(CHECKPOINT_DIR, subfolder)\n",
        "\n",
        "    # If the subfolder doesn't exist, print a message and start from epoch 1\n",
        "    if not os.path.exists(subfolder_path):\n",
        "        print(\"No checkpoint found, starting from epoch 1.\")\n",
        "        return 1, None  # Epoch starts from 1\n",
        "\n",
        "    # Search for checkpoint files in the subfolder that match the hyperparameters\n",
        "    files = [f for f in os.listdir(subfolder_path) if f\"params_{hyperparameters}\" in f and f.endswith('.pth')]\n",
        "\n",
        "    # If checkpoint files are found, load the one with the highest epoch number\n",
        "    if files:\n",
        "        latest_file = max(files, key=lambda x: int(x.split('_')[2]))  # Find the latest epoch file\n",
        "        filepath = os.path.join(subfolder_path, latest_file)\n",
        "        checkpoint = torch.load(filepath, weights_only=True)\n",
        "\n",
        "        # Load the model state from the checkpoint\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        # If an optimizer is provided, load its state as well\n",
        "        if optimizer:\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "        # Try to load the associated JSON file if available\n",
        "        json_filepath = os.path.join(subfolder_path, latest_file.replace('.pth', '.json'))\n",
        "        json_data = None\n",
        "        if os.path.exists(json_filepath):\n",
        "            # If the JSON file exists, load its contents\n",
        "            with open(json_filepath, 'r') as json_file:\n",
        "                json_data = json.load(json_file)\n",
        "            print(\"Data loaded!\")\n",
        "        else:\n",
        "            # If no JSON file exists, print a message\n",
        "            print(\"No data found\")\n",
        "\n",
        "        # Print the epoch from which the model is resuming\n",
        "        print(f\"Checkpoint found: Resuming from epoch {checkpoint['epoch'] + 1}\\n\\n\")\n",
        "        return checkpoint['epoch'] + 1, json_data\n",
        "\n",
        "    # If no checkpoint is found, print a message and start from epoch 1\n",
        "    print(\"No checkpoint found, starting from epoch 1..\\n\\n\")\n",
        "    return 1, None  # Epoch starts from 1\n",
        "\n",
        "def delete_existing_checkpoints(subfolder=\"\"):\n",
        "    \"\"\"\n",
        "    Deletes all existing checkpoints in the specified subfolder.\n",
        "\n",
        "    Arguments:\n",
        "    subfolder -- Optional subfolder within the checkpoint directory to delete checkpoints from.\n",
        "    \"\"\"\n",
        "    subfolder_path = os.path.join(CHECKPOINT_DIR, subfolder)\n",
        "    if os.path.exists(subfolder_path):\n",
        "        for file_name in os.listdir(subfolder_path):\n",
        "            file_path = os.path.join(subfolder_path, file_name)\n",
        "            if os.path.isfile(file_path):\n",
        "                os.remove(file_path)\n",
        "        print(f\"All existing checkpoints in {subfolder_path} have been deleted.\")\n",
        "    else:\n",
        "        print(f\"No checkpoint folder found at {subfolder_path}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVSI_pV5lfmR"
      },
      "source": [
        "# DataLoading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ6fgnHwa0Ai"
      },
      "source": [
        "We must import the dataset manually since it is taken by the LEAF project.\n",
        "\n",
        "So far the project is to go on the data folder of shakespeare and:\n",
        "1. ./get_data.sh inside the preprocess folder\n",
        "2. ./data_to_json.sh\n",
        "3. cd ..\n",
        "3. ././preprocess.sh -s niid --sf 0.2 -k 0 -t sample -tf 0.8 [depending on the preferencies]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "WBh6Mzm_lh7w",
        "outputId": "8127d0a6-6083-4149-d796-49719b45850a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ce19ba42-a650-4266-8d62-4cdd14c0e74d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ce19ba42-a650-4266-8d62-4cdd14c0e74d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving all_data_niid_1_keep_0_train_9.json to all_data_niid_1_keep_0_train_9.json\n"
          ]
        }
      ],
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "file_train = next(iter(uploaded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "RuJV2ApSlltx",
        "outputId": "116a3bc5-38d2-4ed0-c023-d85a36560e27"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b5d0ce55-50d0-46ac-ad74-6a9f24f6ce65\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b5d0ce55-50d0-46ac-ad74-6a9f24f6ce65\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving all_data_niid_1_keep_0_test_9.json to all_data_niid_1_keep_0_test_9.json\n"
          ]
        }
      ],
      "source": [
        "uploaded2 = files.upload()\n",
        "\n",
        "\n",
        "file_test = next(iter(uploaded2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "S_lhyxJalp8z"
      },
      "outputs": [],
      "source": [
        "data = json.load(io.BytesIO(uploaded[file_train]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vehJPpq_lqeu"
      },
      "outputs": [],
      "source": [
        "test_data  = json.load(io.BytesIO(uploaded2[file_test]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LbkTrK1DH7jA"
      },
      "outputs": [],
      "source": [
        "users = test_data['users']\n",
        "num_samples = test_data['num_samples']\n",
        "user_data = test_data['user_data']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jQzejNPIlvSs"
      },
      "outputs": [],
      "source": [
        "#Load the Json file\n",
        "with open(file_train, 'r') as file:\n",
        "    data = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2P8DB4jllyPf"
      },
      "outputs": [],
      "source": [
        "with open(file_test, 'r') as f:\n",
        "    test_data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbR2pJ1WeuLM",
        "outputId": "27418e45-c1d2-41a1-d467-28360ac6dc7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of clients: 63\n"
          ]
        }
      ],
      "source": [
        "num_clients = len(data['users'])\n",
        "print(\"Number of clients:\", num_clients)\n",
        "NUM_CLIENTS = num_clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "i9UliC2qnQUe"
      },
      "outputs": [],
      "source": [
        "users = data['users']\n",
        "num_samples = data['num_samples']\n",
        "user_data = data['user_data']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Y1an7TUynSM3"
      },
      "outputs": [],
      "source": [
        "all_texts = ''.join([''.join(seq) for user in users for seq in user_data[user]['x']])\n",
        "chars = sorted(set(all_texts))\n",
        "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
        "\n",
        "# Add the padding character\n",
        "char_to_idx['<pad>'] = len(char_to_idx)\n",
        "idx_to_char = {idx: ch for ch, idx in char_to_idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDItE3pL82K7"
      },
      "source": [
        "## Convert data into indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SZPpBhzO84qB"
      },
      "outputs": [],
      "source": [
        "inputs = [[char_to_idx[char] for char in user_data[user]['x'][0]] for user in users]\n",
        "targets = [[char_to_idx[char] for char in user_data[user]['y'][0]] for user in users]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL76d_dj86nc"
      },
      "source": [
        "## Creation of TensorDataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "poVRn7mM8_1f"
      },
      "outputs": [],
      "source": [
        "input_tensors = [torch.tensor(seq) for seq in inputs]\n",
        "target_tensors = [torch.tensor([seq]) for seq in targets]\n",
        "\n",
        "chars = sorted(set(all_texts))\n",
        "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
        "char_to_idx['<pad>'] = len(char_to_idx)\n",
        "idx_to_char = {idx: ch for ch, idx in char_to_idx.items()}\n",
        "\n",
        "padded_inputs = pad_sequence(input_tensors, batch_first=True, padding_value=char_to_idx['<pad>'])\n",
        "\n",
        "target_tensors = torch.cat(target_tensors, dim=0)\n",
        "\n",
        "dataset = TensorDataset(padded_inputs, target_tensors)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "OekQphTKnWdt"
      },
      "outputs": [],
      "source": [
        "#for testing porpouses\n",
        "def tensor_to_string(tensor, idx_to_char):\n",
        "    \"\"\"Convert a tensor of indices in a string of characters.\"\"\"\n",
        "    return ''.join(idx_to_char[idx.item()] for idx in tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "U8NgTC39nYK9"
      },
      "outputs": [],
      "source": [
        "# Function to convert character values into indices\n",
        "def char_to_tensor(characters):\n",
        "    indices = [char_to_idx.get(char, char_to_idx['<pad>']) for char in characters] # Get the index for the character. If not found, use the index for padding.\n",
        "    return torch.tensor(indices, dtype=torch.long)\n",
        "\n",
        "# Prepare the training data_loader\n",
        "input_tensors = []\n",
        "target_tensors = []\n",
        "for user in data['users']:\n",
        "    for entry, target in zip(data['user_data'][user]['x'], data['user_data'][user]['y']):\n",
        "        input_tensors.append(char_to_tensor(entry))  # Use the full sequence of x\n",
        "        target_tensors.append(char_to_tensor(target))  # Directly use the corresponding y as target\n",
        "\n",
        "# Padding e creazione di DataLoader\n",
        "padded_inputs = pad_sequence(input_tensors, batch_first=True, padding_value=char_to_idx['<pad>'])\n",
        "targets = torch.cat(target_tensors)\n",
        "dataset = TensorDataset(padded_inputs, targets)\n",
        "# for elem1, elem2 in dataset:\n",
        "#   elem2 = elem2.unsqueeze(0)\n",
        "\n",
        "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5HznZhC1OPx",
        "outputId": "521d10a9-8eca-428e-edeb-bd1fbeccff16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "368469\n"
          ]
        }
      ],
      "source": [
        "# len of the trainig split:\n",
        "print(len(data_loader.dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HrI7p5-wbvVz"
      },
      "outputs": [],
      "source": [
        "# Prepare the training data_loader\n",
        "input_tensors = []\n",
        "target_tensors = []\n",
        "for user in test_data['users']:\n",
        "    for entry, target in zip(test_data['user_data'][user]['x'], test_data['user_data'][user]['y']):\n",
        "        input_tensors.append(char_to_tensor(entry))  # Use the full sequence of x\n",
        "        target_tensors.append(char_to_tensor(target))  # Directly use the corresponding y as target\n",
        "\n",
        "# Padding e creazione di DataLoader\n",
        "padded_inputs = pad_sequence(input_tensors, batch_first=True, padding_value=char_to_idx['<pad>'])\n",
        "targets = torch.cat(target_tensors)\n",
        "dataset = TensorDataset(padded_inputs, targets)\n",
        "# for elem1, elem2 in dataset:\n",
        "#   elem2 = elem2.unsqueeze(0)\n",
        "\n",
        "test_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deLbT6wB1T06",
        "outputId": "9003e9a4-9f2e-4b86-f71e-eb032edcc3db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35998\n"
          ]
        }
      ],
      "source": [
        "# len of the test split:\n",
        "print(len(test_loader.dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMatdM49s63b"
      },
      "source": [
        "# Model inizialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "bWSl31M6DjPg"
      },
      "outputs": [],
      "source": [
        "global_model = CharLSTM(vocab_size=len(char_to_idx))\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFSs3Mk1s-m0"
      },
      "source": [
        "# Client class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ZDhsA-A2DnC1"
      },
      "outputs": [],
      "source": [
        "class Client:\n",
        "    def __init__(self, client_id, data_loader, model, device, char_to_idx):\n",
        "        \"\"\"\n",
        "        Initializes a federated learning client.\n",
        "        :param client_id: Unique identifier for the client.\n",
        "        :param data_loader: Data loader specific to the client.\n",
        "        :param model: The model class to be used by the client.\n",
        "        :param device: The device (CPU/GPU) to perform computations.\n",
        "        \"\"\"\n",
        "        self.client_id = client_id\n",
        "        self.data_loader = data_loader\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "        self.char_to_idx = char_to_idx\n",
        "\n",
        "    def client_update(self, client_data, criterion, optimizer, local_steps=4, detailed_print=False):\n",
        "        \"\"\"\n",
        "        Trains a given client's local model on its dataset for a fixed number of steps (`local_steps`).\n",
        "\n",
        "        Args:\n",
        "            model (nn.Module): The local model to be updated.\n",
        "            client_id (int): Identifier for the client (used for logging/debugging purposes).\n",
        "            client_data (DataLoader): The data loader for the client's dataset.\n",
        "            criterion (Loss): The loss function used for training (e.g., CrossEntropyLoss).\n",
        "            optimizer (Optimizer): The optimizer used for updating model parameters (e.g., SGD).\n",
        "            local_steps (int): Number of local epochs to train on the client's dataset.\n",
        "            detailed_print (bool): If True, logs the final loss after training.\n",
        "\n",
        "        Returns:\n",
        "            dict: The state dictionary of the updated model.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        cudnn.benchmark  # Calling this optimizes runtime\n",
        "\n",
        "        self.model.train()  # Set the model to training mode\n",
        "        step_count = 0\n",
        "        total_loss = 0.0\n",
        "        correct_predictions = 0\n",
        "        total_samples = 0\n",
        "        while step_count < local_steps:\n",
        "            for data, targets in client_data:\n",
        "                # Move data and targets to the specified device (e.g., GPU or CPU)\n",
        "                data, targets = data.to(self.device), targets.to(self.device)\n",
        "\n",
        "\n",
        "                start_time = time.time()  # for testing-----------------------------\n",
        "\n",
        "                # Reset the gradients before backpropagation\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                hidden = self.model.init_hidden(data.size(0))\n",
        "                hidden = (hidden[0].to(DEVICE), hidden[1].to(DEVICE))\n",
        "\n",
        "                # Forward pass: compute model predictions\n",
        "                outputs, _ = self.model(data, hidden)\n",
        "\n",
        "                output_flat = outputs.view(-1, len(self.char_to_idx))\n",
        "                targets_flat = targets.view(-1)\n",
        "                # loss = criterion(output_flat, targets_flat)\n",
        "\n",
        "                # Compute the loss\n",
        "                loss = criterion(output_flat, targets_flat)\n",
        "\n",
        "                # # Backward pass: compute gradients and update weights\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                #---------- Accumulate metrics\n",
        "                #  Accumulates the weighted loss for the number of samples in the batch to account for any variation in\n",
        "                #  batch size due to, for example, the smaller final batch. A little too precise? :)\n",
        "                total_loss += loss.item() * data.size(0)\n",
        "                _, predicted = output_flat.max(1)\n",
        "                correct_predictions += predicted.eq(targets).sum().item()\n",
        "                total_samples += data.size(0)\n",
        "\n",
        "                step_count +=1\n",
        "                if step_count >= local_steps:\n",
        "                  break\n",
        "\n",
        "        #---------- Compute averaged metrics\n",
        "        avg_loss = total_loss / total_samples\n",
        "        avg_accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "        # Optionally, print the loss for the last epoch of training\n",
        "        if detailed_print:\n",
        "          print(f'Client {self.client_id} --> Final Loss (Step {step_count}/{local_steps}): {loss.item()}')\n",
        "\n",
        "\n",
        "        # Return the updated model's state dictionary (weights)\n",
        "        return self.model.state_dict(), avg_loss, avg_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPy9RrSMtB1U"
      },
      "source": [
        "# Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CSdo3O9eoBFv"
      },
      "outputs": [],
      "source": [
        "DIR = '/content/drive/MyDrive/colab_plots/'\n",
        "\n",
        "def plot_client_selection(client_selection_count, file_name):\n",
        "    \"\"\"\n",
        "    Bar plot to visualize the frequency of client selections in a federated learning simulation.\n",
        "\n",
        "    Args:\n",
        "        client_selection_count (list): list containing the number of times each client was selected.\n",
        "        file_name (str): name of the file to save the plot.\n",
        "    \"\"\"\n",
        "    # Fixed base directory\n",
        "    directory = DIR +  'plots_federated/'\n",
        "    # Ensure the base directory exists\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "    # Complete path for the file\n",
        "    file_path = os.path.join(directory, file_name)\n",
        "\n",
        "    num_clients = len(client_selection_count)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(range(num_clients), client_selection_count, alpha=0.7, edgecolor='black')\n",
        "    plt.xlabel(\"Client ID\", fontsize=14)\n",
        "    plt.ylabel(\"Selection Count\", fontsize=14)\n",
        "    plt.title(\"Client Selection Frequency\", fontsize=16)\n",
        "    plt.xticks(range(num_clients), fontsize=10, rotation=90 if num_clients > 20 else 0)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(file_path, format=\"png\", dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Utility function used both in the centralized and federated learning\n",
        "Computes the accuracy and the loss on the validation/test set depending on the dataloader passed\n",
        "\"\"\"\n",
        "def evaluate(model, dataloader, criterion, DEVICE):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    running_corrects = 0\n",
        "    total_samples = 0  # Total samples counter\n",
        "    losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, targets in dataloader:\n",
        "            data = data.to(DEVICE)\n",
        "            targets = targets.to(DEVICE)\n",
        "            hidden = model.init_hidden(data.size(0))\n",
        "            hidden = (hidden[0].to(DEVICE), hidden[1].to(DEVICE))\n",
        "            outputs, _ = model(data, hidden)\n",
        "            outputs_flat = outputs.view(-1, model.vocab_size)\n",
        "            targets_flat = targets.view(-1)\n",
        "\n",
        "            loss = criterion(outputs_flat, targets_flat)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            _, preds = outputs_flat.max(1)\n",
        "            #running_corrects += torch.sum(preds == targets_flat).item()\n",
        "            running_corrects += (preds == targets_flat).sum().item()\n",
        "            total_samples += targets_flat.size(0)\n",
        "\n",
        "    accuracy = (running_corrects / total_samples) * 100\n",
        "    return accuracy, sum(losses) / len(losses)\n",
        "\n",
        "\n",
        "def test(global_model, test_loader, criterion, DEVICE):\n",
        "    \"\"\"\n",
        "    Evaluate the global model on the test dataset.\n",
        "\n",
        "    Args:\n",
        "        global_model (nn.Module): The global model to be evaluated.\n",
        "        test_loader (DataLoader): DataLoader for the test dataset.\n",
        "\n",
        "    Returns:\n",
        "        float: The accuracy of the model on the test dataset.\n",
        "        float: The loss of the model on the test dataset.\n",
        "    \"\"\"\n",
        "    test_accuracy, loss = evaluate(global_model, test_loader, criterion, DEVICE)\n",
        "    return test_accuracy, loss\n",
        "\n",
        "def plot_metrics(train_accuracies, train_losses, file_name):\n",
        "    \"\"\"\n",
        "    Plot the training metrics for a federated learning simulation.\n",
        "\n",
        "    Args:\n",
        "        train_accuracies (list): List of training accuracies.\n",
        "        train_losses (list): List of training losses.\n",
        "        file_name (str): Name of the file to save the plot.\n",
        "    \"\"\"\n",
        "    # Fixed base directory\n",
        "    directory = DIR + '/plots_federated/'\n",
        "    # Ensure the base directory exists\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "    # Complete path for the file\n",
        "    file_path = os.path.join(directory, file_name)\n",
        "\n",
        "    # Create a list of epochs for the x-axis\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "\n",
        "    # Plot the training loss\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, train_losses, label='Train Loss', color='blue')\n",
        "    plt.xlabel('Rounds', fontsize=14)\n",
        "    plt.ylabel('Loss', fontsize=14)\n",
        "    plt.title('Training Loss', fontsize=16)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(file_path.replace('.png', '_loss.png'), format='png', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # Plot the training accuracy\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, train_accuracies, label='Train Accuracy', color='blue')\n",
        "    plt.xlabel('Rounds', fontsize=14)\n",
        "    plt.ylabel('Accuracy', fontsize=14)\n",
        "    plt.title('Training Accuracy', fontsize=16)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(file_path.replace('.png', '_accuracy.png'), format='png', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def save_data(global_model, train_accuracies, train_losses,client_count, file_name):\n",
        "    \"\"\"\n",
        "    Save the global model, train_accuracies,train_losses and client_count to a file.\n",
        "\n",
        "    Args:\n",
        "        global_model (nn.Module): The global model to be saved.\n",
        "        train_accuracies (list): List of training accuracies.\n",
        "        train_losses (list): List of training losses.\n",
        "        file_name (str): Name of the file to save the data.\n",
        "    \"\"\"\n",
        "    # Fixed base directory\n",
        "    directory = DIR + '/trained_models/'\n",
        "    # Ensure the base directory exists\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "    # Complete path for the file\n",
        "    file_path = os.path.join(directory, file_name)\n",
        "\n",
        "    # Save all data (model state and metrics) into a dictionary\n",
        "    save_dict = {\n",
        "        'model_state': global_model.state_dict(),\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'train_losses': train_losses,\n",
        "        'client_count': client_count\n",
        "    }\n",
        "\n",
        "    # Save the dictionary to the specified file\n",
        "    torch.save(save_dict, file_path)\n",
        "    print(f\"Data saved successfully to {file_path}\")\n",
        "\n",
        "def load_data(model, file_name):\n",
        "    \"\"\"\n",
        "    Load the model weights and metrics from a file.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The model to load the weights into.\n",
        "        file_name (str): Name of the file to load the data from.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the model, train_accuracies train_losses and client_count.\n",
        "    \"\"\"\n",
        "    # Fixed base directory\n",
        "    directory = DIR+ 'trained_models/'\n",
        "    # Complete path for the file\n",
        "    file_path = os.path.join(directory, file_name)\n",
        "\n",
        "    # Load the saved data from the specified file\n",
        "    save_dict = torch.load(file_path)\n",
        "\n",
        "    # Load the model state\n",
        "    model.load_state_dict(save_dict['model_state'])\n",
        "\n",
        "    # Extract the metrics\n",
        "    train_accuracies = save_dict['train_accuracies']\n",
        "    train_losses = save_dict['train_losses']\n",
        "    client_count = save_dict['client_count']\n",
        "\n",
        "    print(f\"Data loaded successfully from {file_path}\")\n",
        "\n",
        "    return model, train_accuracies, train_losses,client_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKOAtAEftE1R"
      },
      "source": [
        "# Server class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2mU8_ccaD6Mu"
      },
      "outputs": [],
      "source": [
        "log = logging.getLogger(__name__)\n",
        "\n",
        "class Server:\n",
        "    def __init__(self, global_model, device, char_to_idx, CHECKPOINT_DIR):\n",
        "        self.global_model = global_model\n",
        "        self.device = device\n",
        "        self.char_to_idx = char_to_idx\n",
        "        self.CHECKPOINT_DIR = CHECKPOINT_DIR\n",
        "        # Ensure the checkpoint directory exists, creating it if necessary\n",
        "        os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "    def save_checkpoint(self, model, optimizer, epoch, hyperparameters, subfolder=\"\", checkpoint_data=None):\n",
        "        \"\"\"\n",
        "        Saves the model checkpoint and removes the previous one if it exists.\n",
        "\n",
        "        Arguments:\n",
        "        model -- The model whose state is to be saved.\n",
        "        optimizer -- The optimizer whose state is to be saved (can be None).\n",
        "        epoch -- The current epoch of the training process.\n",
        "        hyperparameters -- A string representing the model's hyperparameters for file naming.\n",
        "        subfolder -- Optional subfolder within the checkpoint directory to save the checkpoint.\n",
        "        checkpoint_data -- Data to save in a JSON file (e.g., training logs).\n",
        "        \"\"\"\n",
        "        # Define the path for the subfolder where checkpoints will be stored\n",
        "        subfolder_path = os.path.join(self.CHECKPOINT_DIR, subfolder)\n",
        "        # Create the subfolder if it doesn't exist\n",
        "        os.makedirs(subfolder_path, exist_ok=True)\n",
        "\n",
        "        # Construct filenames for both the model checkpoint and the associated JSON file\n",
        "        filename = f\"model_epoch_{epoch}_params_{hyperparameters}.pth\"\n",
        "        filepath = os.path.join(subfolder_path, filename)\n",
        "        filename_json = f\"model_epoch_{epoch}_params_{hyperparameters}.json\"\n",
        "        filepath_json = os.path.join(subfolder_path, filename_json)\n",
        "\n",
        "        # Define the filenames for the previous checkpoint files, to remove them if necessary\n",
        "        previous_filepath = os.path.join(subfolder_path, f\"model_epoch_{epoch - 1}_params_{hyperparameters}.pth\")\n",
        "        previous_filepath_json = os.path.join(subfolder_path, f\"model_epoch_{epoch - 1}_params_{hyperparameters}.json\")\n",
        "\n",
        "        # Remove the previous checkpoint if it exists, but only for epochs greater than 1\n",
        "        if epoch > 1 and os.path.exists(previous_filepath):\n",
        "            os.remove(previous_filepath)\n",
        "            os.remove(previous_filepath_json)\n",
        "\n",
        "        # Prepare the checkpoint data dictionary\n",
        "        checkpoint = {'model_state_dict': model.state_dict(), 'epoch': epoch}\n",
        "        # If an optimizer is provided, save its state as well\n",
        "        if optimizer is not None:\n",
        "            checkpoint['optimizer_state_dict'] = optimizer.state_dict()\n",
        "\n",
        "        # Save the model and optimizer (if provided) state dictionary to the checkpoint file\n",
        "        torch.save(checkpoint, filepath)\n",
        "        print(f\"Checkpoint saved: {filepath}\")\n",
        "\n",
        "        # If additional data (e.g., training logs) is provided, save it to a JSON file\n",
        "        if checkpoint_data:\n",
        "            with open(filepath_json, 'w') as json_file:\n",
        "                json.dump(checkpoint_data, json_file, indent=4)\n",
        "\n",
        "    def load_checkpoint(self, model, optimizer, hyperparameters, subfolder=\"\"):\n",
        "        \"\"\"\n",
        "        Loads the latest checkpoint available based on the specified hyperparameters.\n",
        "\n",
        "        Arguments:\n",
        "        model -- The model whose state will be updated from the checkpoint.\n",
        "        optimizer -- The optimizer whose state will be updated from the checkpoint (can be None).\n",
        "        hyperparameters -- A string representing the model's hyperparameters for file naming.\n",
        "        subfolder -- Optional subfolder within the checkpoint directory to look for checkpoints.\n",
        "\n",
        "        Returns:\n",
        "        The next epoch to resume from and the associated JSON data if available.\n",
        "        \"\"\"\n",
        "        # Define the path to the subfolder where checkpoints are stored\n",
        "        subfolder_path = os.path.join(self.CHECKPOINT_DIR, subfolder)\n",
        "\n",
        "        # If the subfolder doesn't exist, print a message and start from epoch 1\n",
        "        if not os.path.exists(subfolder_path):\n",
        "            print(\"No checkpoint found, starting from epoch 1.\")\n",
        "            return 1, None  # Epoch starts from 1\n",
        "\n",
        "        # Search for checkpoint files in the subfolder that match the hyperparameters\n",
        "        files = [f for f in os.listdir(subfolder_path) if f\"params_{hyperparameters}\" in f and f.endswith('.pth')]\n",
        "\n",
        "        # If checkpoint files are found, load the one with the highest epoch number\n",
        "        if files:\n",
        "            latest_file = max(files, key=lambda x: int(x.split('_')[2]))  # Find the latest epoch file\n",
        "            filepath = os.path.join(subfolder_path, latest_file)\n",
        "            checkpoint = torch.load(filepath, weights_only=True)\n",
        "\n",
        "            # Load the model state from the checkpoint\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            # If an optimizer is provided, load its state as well\n",
        "            if optimizer:\n",
        "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "            # Try to load the associated JSON file if available\n",
        "            json_filepath = os.path.join(subfolder_path, latest_file.replace('.pth', '.json'))\n",
        "            json_data = None\n",
        "            if os.path.exists(json_filepath):\n",
        "                # If the JSON file exists, load its contents\n",
        "                with open(json_filepath, 'r') as json_file:\n",
        "                    json_data = json.load(json_file)\n",
        "                print(\"Data loaded!\")\n",
        "            else:\n",
        "                # If no JSON file exists, print a message\n",
        "                print(\"No data found\")\n",
        "\n",
        "            # Print the epoch from which the model is resuming\n",
        "            print(f\"Checkpoint found: Resuming from epoch {checkpoint['epoch'] + 1}\\n\\n\")\n",
        "            return checkpoint['epoch'] + 1, json_data\n",
        "\n",
        "        # If no checkpoint is found, print a message and start from epoch 1\n",
        "        print(\"No checkpoint found, starting from epoch 1..\\n\\n\")\n",
        "        return 1, None  # Epoch starts from 1\n",
        "\n",
        "    def delete_existing_checkpoints(self, subfolder=\"\"):\n",
        "        \"\"\"\n",
        "        Deletes all existing checkpoints in the specified subfolder.\n",
        "\n",
        "        Arguments:\n",
        "        subfolder -- Optional subfolder within the checkpoint directory to delete checkpoints from.\n",
        "        \"\"\"\n",
        "        subfolder_path = os.path.join(self.CHECKPOINT_DIR, subfolder)\n",
        "        if os.path.exists(subfolder_path):\n",
        "            for file_name in os.listdir(subfolder_path):\n",
        "                file_path = os.path.join(subfolder_path, file_name)\n",
        "                if os.path.isfile(file_path):\n",
        "                    os.remove(file_path)\n",
        "            print(f\"All existing checkpoints in {subfolder_path} have been deleted.\")\n",
        "        else:\n",
        "            print(f\"No checkpoint folder found at {subfolder_path}.\")\n",
        "\n",
        "    def char_to_tensor(self, characters):\n",
        "        indices = [self.char_to_idx.get(char, self.char_to_idx['<pad>']) for char in characters] # Get the index for the character. If not found, use the index for padding.\n",
        "        return torch.tensor(indices, dtype=torch.long)\n",
        "\n",
        "    def fedavg_aggregate(self, client_states, client_sizes, client_avg_losses, client_avg_accuracies):\n",
        "        \"\"\"\n",
        "        Aggregates model updates and client metrics from selected clients using the Federated Averaging (FedAvg) algorithm.\n",
        "        The updates and metrics are weighted by the size of each client's dataset.\n",
        "\n",
        "        Args:\n",
        "            global_model (nn.Module): The global model whose structure is used for aggregation.\n",
        "            client_states (list[dict]): A list of state dictionaries (model weights) from participating clients.\n",
        "            client_sizes (list[int]): A list of dataset sizes for the participating clients.\n",
        "            client_avg_losses (list[float]): A list of average losses for the participating clients.\n",
        "            client_avg_accuracies (list[float]): A list of average accuracies for the participating clients.\n",
        "\n",
        "        Returns:\n",
        "            tuple: The aggregated state dictionary with updated model parameters, global average loss, and global average accuracy.\n",
        "        \"\"\"\n",
        "        # Copy the global model's state dictionary for aggregation\n",
        "        new_state = deepcopy(self.global_model.state_dict())\n",
        "\n",
        "        # Calculate the total number of samples across all participating clients\n",
        "        total_samples = sum(client_sizes)\n",
        "\n",
        "        # Initialize all parameters in the new state to zero\n",
        "        for key in new_state:\n",
        "            new_state[key] = torch.zeros_like(new_state[key])\n",
        "\n",
        "        # Initialize metrics\n",
        "        total_loss = 0.0\n",
        "        total_accuracy = 0.0\n",
        "\n",
        "        # Perform a weighted average of client updates and metrics\n",
        "        for state, size, avg_loss, avg_accuracy in zip(client_states, client_sizes, client_avg_losses, client_avg_accuracies):\n",
        "            for key in new_state:\n",
        "                # Add the weighted contribution of each client's parameters\n",
        "                new_state[key] += (state[key] * size / total_samples)\n",
        "            total_loss += avg_loss * size\n",
        "            total_accuracy += avg_accuracy * size\n",
        "\n",
        "        # Calculate global metrics\n",
        "        global_avg_loss = total_loss / total_samples\n",
        "        global_avg_accuracy = total_accuracy / total_samples\n",
        "\n",
        "        # Return the aggregated state dictionary with updated weights and global metrics\n",
        "        return new_state, global_avg_loss, global_avg_accuracy\n",
        "\n",
        "\n",
        "    # Federated Learning Training Loop\n",
        "    def train_federated(self, criterion, raw_data, num_clients, rounds, lr, momentum, batchsize, wd, C=0.1, local_steps=4, log_freq=10, detailed_print=True,gamma=None):\n",
        "        # val_accuracies = []\n",
        "        # val_losses = []\n",
        "        train_accuracies = []\n",
        "        train_losses = []\n",
        "        #print(\"num clients: \",num_clients)\n",
        "        best_model_state = None  # The model with the best accuracy\n",
        "        client_selection_count = [0] * num_clients #Count how many times a client has been selected\n",
        "        #best_val_acc = 0.0\n",
        "        best_train_loss = float('inf')\n",
        "\n",
        "        shards = self.sharding(raw_data) #each shard represent the training data for one client\n",
        "        client_sizes = [len(shard) for shard in shards]\n",
        "        #print(\"client sizes: \", client_sizes)\n",
        "\n",
        "        self.global_model.to(self.device) #as alwayse, we move the global model to the specified device (CPU or GPU)\n",
        "\n",
        "        #loading checkpoint if it exists\n",
        "        # checkpoint_start_step, data_to_load = load_checkpoint(model=self.global_model,optimizer=None,hyperparameters=f\"LR{lr}_WD{wd}\", subfolder=\"Federated/\")\n",
        "        # if data_to_load is not None:\n",
        "        #   train_accuracies = data_to_load['train_accuracies']\n",
        "        #   train_losses = data_to_load['train_losses']\n",
        "        #   client_selection_count = data_to_load['client_selection_count']\n",
        "        probabilities = None\n",
        "        if gamma is not None:\n",
        "            probabilities = self.skewed_probabilities(num_clients, gamma)\n",
        "\n",
        "        # ********************* HOW IT WORKS ***************************************\n",
        "        # The training runs for rounds iterations (GLOBAL_ROUNDS=200)\n",
        "        # Each round simulates one communication step in federated learning, including:\n",
        "        # 1) client selection\n",
        "        # 2) local training (of each client)\n",
        "        # 3) central aggregation\n",
        "        for round_num in range(rounds):\n",
        "            if (round_num+1) % log_freq == 0 and detailed_print:\n",
        "              print(f\"------------------------------------- Round {round_num+1} ------------------------------------------------\" )\n",
        "\n",
        "            # 1) client selection: In each round, a fraction C (e.g., 10%) of clients is randomly selected to participate.\n",
        "            #     This reduces computation costs and mimics real-world scenarios where not all devices are active.\n",
        "            selected_clients = self.client_selection(num_clients, C,probabilities)\n",
        "            client_states = []\n",
        "            client_avg_losses = []\n",
        "            client_avg_accuracies = []\n",
        "            for client_id in selected_clients:\n",
        "                client_selection_count[client_id] += 1\n",
        "\n",
        "            # 2) local training: for each client updates the model using the client's data for local_steps epochs\n",
        "            for client_id in selected_clients:\n",
        "                local_model = deepcopy(self.global_model) #it creates a local copy of the global model\n",
        "                optimizer = optim.SGD(local_model.parameters(), lr=lr, momentum=momentum, weight_decay=wd)\n",
        "                client_loader = DataLoader(shards[client_id], batch_size=batchsize, shuffle=True)\n",
        "\n",
        "                print_log =  (round_num+1) % log_freq == 0 and detailed_print\n",
        "                client = Client(client_id, client_loader, local_model, self.device, self.char_to_idx)\n",
        "                client_local_state, client_avg_loss, client_avg_accuracy  = client.client_update(client_loader, criterion, optimizer, local_steps, print_log)\n",
        "\n",
        "                client_states.append(client_local_state)\n",
        "                client_avg_losses.append(client_avg_loss)\n",
        "                client_avg_accuracies.append(client_avg_accuracy)\n",
        "\n",
        "\n",
        "            # 3) central aggregation: aggregates participating client updates using fedavg_aggregate\n",
        "            #    and replaces the current parameters of global_model with the returned ones.\n",
        "            aggregated_state, train_loss, train_accuracy = self.fedavg_aggregate(client_states, [client_sizes[i] for i in selected_clients], client_avg_losses, client_avg_accuracies)\n",
        "\n",
        "            self.global_model.load_state_dict(aggregated_state)\n",
        "\n",
        "            train_accuracies.append(train_accuracy)\n",
        "            train_losses.append(train_loss)\n",
        "            # #Validation at the server\n",
        "            # val_accuracy, val_loss = evaluate(self.global_model, validloader)\n",
        "            # val_accuracies.append(val_accuracy)\n",
        "            # val_losses.append(val_loss)\n",
        "            if train_loss < best_train_loss:\n",
        "                best_train_loss = train_loss\n",
        "                best_model_state = deepcopy(self.global_model.state_dict())\n",
        "\n",
        "            if (round_num+1) % log_freq == 0:\n",
        "                if detailed_print:\n",
        "                    print(f\"-->training accuracy: {train_accuracy:.2f}\")\n",
        "                    print(f\"-->training loss: {train_loss:.4f}\")\n",
        "\n",
        "                # checkpointing\n",
        "                checkpoint_data = {\n",
        "                    'train_accuracies': train_accuracies,\n",
        "                    'train_losses': train_losses,\n",
        "                    'client_selection_count': client_selection_count\n",
        "                }\n",
        "                self.save_checkpoint(self.global_model,optimizer=None, epoch=round_num, hyperparameters=f\"LR{lr}_WD{wd}\", subfolder=\"Federated/\", checkpoint_data=checkpoint_data)\n",
        "                if detailed_print:\n",
        "                    print(f\"------------------------------ Round {round_num+1} terminated: model updated -----------------------------\\n\\n\" )\n",
        "\n",
        "        self.global_model.load_state_dict(best_model_state)\n",
        "\n",
        "        return self.global_model, train_accuracies, train_losses, client_selection_count\n",
        "\n",
        "    def skewed_probabilities(self, number_of_clients, gamma=0.5):\n",
        "            # Generate skewed probabilities using a Dirichlet distribution\n",
        "            probabilities = np.random.dirichlet(np.ones(number_of_clients) * gamma)\n",
        "            return probabilities\n",
        "\n",
        "    def client_selection(self,number_of_clients, clients_fraction, probabilities=None):\n",
        "        \"\"\"\n",
        "        Selects a subset of clients based on uniform or skewed distribution.\n",
        "\n",
        "        Args:\n",
        "        number_of_clients (int): Total number of clients.\n",
        "        clients_fraction (float): Fraction of clients to be selected.\n",
        "        uniform (bool): If True, selects clients uniformly. If False, selects clients based on a skewed distribution.\n",
        "        gamma (float): Hyperparameter for the Dirichlet distribution controlling the skewness (only used if uniform=False).\n",
        "\n",
        "        Returns:\n",
        "        list: List of selected client indices.\n",
        "        \"\"\"\n",
        "        num_clients_to_select = int(number_of_clients * clients_fraction)\n",
        "\n",
        "        if probabilities is None:\n",
        "            # Uniformly select clients without replacement\n",
        "            selected_clients = np.random.choice(number_of_clients, num_clients_to_select, replace=False)\n",
        "        else:\n",
        "            selected_clients = np.random.choice(number_of_clients, num_clients_to_select, replace=False, p=probabilities)\n",
        "\n",
        "        return selected_clients\n",
        "\n",
        "\n",
        "\n",
        "    def sharding(self, data):\n",
        "        \"\"\"\n",
        "        Prepares individual shards for each user, returning a Subset for each.\n",
        "\n",
        "        Args:\n",
        "        data (dict): Dataset containing user data.\n",
        "        char_to_idx (dict): Character to index mapping dictionary for character conversion.\n",
        "\n",
        "        Returns:\n",
        "        list: List of Subsets, one for each user.\n",
        "        \"\"\"\n",
        "        subsets = []\n",
        "\n",
        "        for user in data['users']:\n",
        "            input_tensors = []\n",
        "            target_tensors = []\n",
        "\n",
        "            for entry, target in zip(data['user_data'][user]['x'], data['user_data'][user]['y']):\n",
        "              input_tensors.append(self.char_to_tensor(entry))  # Use the full sequence of x\n",
        "              target_tensors.append(self.char_to_tensor(target))  # Directly use the corresponding y as target\n",
        "\n",
        "            # Padding inputs to ensure all inputs in a batch have the same length\n",
        "            padded_inputs = pad_sequence(input_tensors, batch_first=True, padding_value=self.char_to_idx['<pad>'])\n",
        "            targets = torch.cat(target_tensors)\n",
        "\n",
        "            # Creating the TensorDataset for the user\n",
        "            dataset = TensorDataset(padded_inputs, targets)\n",
        "\n",
        "            # Since each user is treated as a separate \"client\", we create a Subset for each\n",
        "            subsets.append(Subset(dataset, torch.arange(len(targets))))\n",
        "\n",
        "        return subsets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57d-hbzJBW0G"
      },
      "source": [
        "# Training cycle and testing results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZWIWzOFQnqq",
        "outputId": "a3896416-46eb-418b-a71f-ffd5111c90e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CrossEntropyLoss()\n"
          ]
        }
      ],
      "source": [
        "print(criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcMKM5CbQpoU",
        "outputId": "eb3fe8e1-1693-4dc1-af8a-ba60c98ba1a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63\n"
          ]
        }
      ],
      "source": [
        "print(num_clients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnVBGFsgQulq",
        "outputId": "b13bcaac-85e5-4fff-9744-5fc4d55516af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n"
          ]
        }
      ],
      "source": [
        "print(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtA9ACEhQyCc",
        "outputId": "4dbd99ea-b4f7-4288-e5b8-4fa020a99564"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.1\n"
          ]
        }
      ],
      "source": [
        "print(FRACTION_CLIENTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa40GJkL-oVe",
        "outputId": "691381e2-57e1-4381-ff29-1f93299b941c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n"
          ]
        }
      ],
      "source": [
        "print(MOMENTUM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ-REjRABY3F",
        "outputId": "64573dfc-1ef1-4257-9553-d469ac19531c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running experiment: local_steps=4\n",
            "------------------------------------- Round 100 ------------------------------------------------\n",
            "Client 0 --> Final Loss (Step 4/4): 3.0484912395477295\n",
            "Client 44 --> Final Loss (Step 4/4): 2.900583267211914\n",
            "Client 43 --> Final Loss (Step 4/4): 2.853752851486206\n",
            "Client 54 --> Final Loss (Step 4/4): 2.8242075443267822\n",
            "Client 59 --> Final Loss (Step 4/4): 2.807734966278076\n",
            "Client 14 --> Final Loss (Step 4/4): 3.1103081703186035\n",
            "-->training accuracy: 25.16\n",
            "-->training loss: 2.7717\n",
            "Checkpoint saved: /content/drive/MyDrive/colab_checkpoints/Federated/model_epoch_99_params_LR1.0_WD0.0001.pth\n",
            "------------------------------ Round 100 terminated: model updated -----------------------------\n",
            "\n",
            "\n",
            "------------------------------------- Round 200 ------------------------------------------------\n",
            "Client 53 --> Final Loss (Step 4/4): 2.285294532775879\n",
            "Client 49 --> Final Loss (Step 4/4): 2.6715526580810547\n",
            "Client 17 --> Final Loss (Step 4/4): 2.417442798614502\n",
            "Client 35 --> Final Loss (Step 4/4): 2.4156100749969482\n",
            "Client 1 --> Final Loss (Step 4/4): 2.582500696182251\n",
            "Client 4 --> Final Loss (Step 4/4): 2.5140817165374756\n",
            "-->training accuracy: 32.81\n",
            "-->training loss: 2.4175\n",
            "Checkpoint saved: /content/drive/MyDrive/colab_checkpoints/Federated/model_epoch_199_params_LR1.0_WD0.0001.pth\n",
            "------------------------------ Round 200 terminated: model updated -----------------------------\n",
            "\n",
            "\n",
            "------------------------------------- Round 300 ------------------------------------------------\n",
            "Client 37 --> Final Loss (Step 4/4): 2.3516969680786133\n",
            "Client 28 --> Final Loss (Step 4/4): 2.434907913208008\n",
            "Client 5 --> Final Loss (Step 4/4): 2.1648619174957275\n",
            "Client 62 --> Final Loss (Step 4/4): 2.327263116836548\n",
            "Client 6 --> Final Loss (Step 4/4): 2.2830753326416016\n",
            "Client 57 --> Final Loss (Step 4/4): 2.2683892250061035\n",
            "-->training accuracy: 35.37\n",
            "-->training loss: 2.2627\n",
            "Checkpoint saved: /content/drive/MyDrive/colab_checkpoints/Federated/model_epoch_299_params_LR1.0_WD0.0001.pth\n",
            "------------------------------ Round 300 terminated: model updated -----------------------------\n",
            "\n",
            "\n",
            "------------------------------------- Round 400 ------------------------------------------------\n",
            "Client 10 --> Final Loss (Step 4/4): 1.974770188331604\n",
            "Client 37 --> Final Loss (Step 4/4): 2.4099690914154053\n",
            "Client 30 --> Final Loss (Step 4/4): 2.0664708614349365\n",
            "Client 25 --> Final Loss (Step 4/4): 2.314840316772461\n",
            "Client 29 --> Final Loss (Step 4/4): 2.1259963512420654\n",
            "Client 12 --> Final Loss (Step 4/4): 2.4231150150299072\n",
            "-->training accuracy: 37.77\n",
            "-->training loss: 2.1511\n",
            "Checkpoint saved: /content/drive/MyDrive/colab_checkpoints/Federated/model_epoch_399_params_LR1.0_WD0.0001.pth\n",
            "------------------------------ Round 400 terminated: model updated -----------------------------\n",
            "\n",
            "\n",
            "------------------------------------- Round 500 ------------------------------------------------\n",
            "Client 37 --> Final Loss (Step 4/4): 2.2556064128875732\n",
            "Client 58 --> Final Loss (Step 4/4): 2.082425355911255\n",
            "Client 11 --> Final Loss (Step 4/4): 1.849583387374878\n",
            "Client 42 --> Final Loss (Step 4/4): 2.0439178943634033\n",
            "Client 27 --> Final Loss (Step 4/4): 2.002519369125366\n",
            "Client 46 --> Final Loss (Step 4/4): 2.1815903186798096\n",
            "-->training accuracy: 40.13\n",
            "-->training loss: 2.1052\n",
            "Checkpoint saved: /content/drive/MyDrive/colab_checkpoints/Federated/model_epoch_499_params_LR1.0_WD0.0001.pth\n",
            "------------------------------ Round 500 terminated: model updated -----------------------------\n",
            "\n",
            "\n",
            "------------------------------------- Round 600 ------------------------------------------------\n",
            "Client 37 --> Final Loss (Step 4/4): 1.6940677165985107\n",
            "Client 36 --> Final Loss (Step 4/4): 2.054084539413452\n",
            "Client 34 --> Final Loss (Step 4/4): 2.040597915649414\n",
            "Client 26 --> Final Loss (Step 4/4): 2.0010721683502197\n",
            "Client 23 --> Final Loss (Step 4/4): 2.2574727535247803\n",
            "Client 27 --> Final Loss (Step 4/4): 1.943089485168457\n",
            "-->training accuracy: 41.99\n",
            "-->training loss: 1.9910\n",
            "Checkpoint saved: /content/drive/MyDrive/colab_checkpoints/Federated/model_epoch_599_params_LR1.0_WD0.0001.pth\n",
            "------------------------------ Round 600 terminated: model updated -----------------------------\n",
            "\n",
            "\n",
            "Test accuracy for local_steps=4: 42.63014611922885\n",
            "Data saved successfully to /content/drive/MyDrive/colab_plots//trained_models/Federated_LR_1.0_WD_0.0001_j_4.pth\n"
          ]
        }
      ],
      "source": [
        "lr = 1.0\n",
        "wd = 0.0001\n",
        "'''\n",
        "These hyperparameters are taken from:\n",
        "Acar, Durmus Alp Emre, et al. \"Federated learning based on dynamic regularization.\" arXiv preprint arXiv:2111.04263 (2021).\n",
        "\n",
        "Notice infact that the leaf version of the Shakespeare dataset doesn't come with a linked validation dataset to\n",
        "choose the most accurate hyperparameters.\n",
        "'''\n",
        "\n",
        "local_steps =4\n",
        "LOCAL_STEPS_VALUES = [4, 8, 16]  # Values for J (number of local steps)\n",
        "NUM_RUNDS = {4: 200, 8: 100, 16:50}\n",
        "print(f\"Running experiment: local_steps={local_steps}\")\n",
        "global_model = CharLSTM(vocab_size=len(char_to_idx))\n",
        "server = Server(global_model, DEVICE, char_to_idx, CHECKPOINT_DIR)\n",
        "\n",
        "    #tuning_rounds = int(NUM_RUNDS[local_steps]/20)\n",
        "    #best_lr, best_wd = to be manually set\n",
        "\n",
        "global_model, train_accuracies, train_losses, client_selection_count = server.train_federated(\n",
        "        criterion, data,\n",
        "        num_clients=NUM_CLIENTS,\n",
        "        rounds=NUM_RUNDS[local_steps], lr=lr, momentum=MOMENTUM,\n",
        "        batchsize=BATCH_SIZE, wd=wd, C=FRACTION_CLIENTS,\n",
        "        local_steps=local_steps, log_freq=100,\n",
        "        detailed_print=True, gamma=None  # No skewed sampling for this experiment\n",
        ")\n",
        "\n",
        "# Testing and plotting\n",
        "test_accuracy, test_loss = test(global_model, test_loader, criterion, DEVICE)\n",
        "plot_metrics(train_accuracies, train_losses, f\"Federated_scaled_LR_{lr}_WD_{wd}.png\")\n",
        "print(f\"Test accuracy for local_steps={local_steps}: {test_accuracy}\")\n",
        "\n",
        "# Save data for future analysis\n",
        "save_data(global_model, train_accuracies, train_losses, client_selection_count, f\"Federated_LR_{lr}_WD_{wd}_j_{local_steps}.pth\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
