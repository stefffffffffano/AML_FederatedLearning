{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments related to the personal contribution\n",
    "EA algorithm to enhance client selection in the federated setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "First, import of necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from models.model import LeNet5 \n",
    "sys.path.append('../data/cifar100/')\n",
    "from cifar100_loader import CIFAR100DataLoader\n",
    "from utils.federated_utils import plot_metrics,test, plot_client_selection,save_data,load_data\n",
    "from EA_algorithm import EA_algorithm\n",
    "\n",
    "BATCH_SIZE = 64 #constant\n",
    "GLOBAL_ROUNDS = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#10% of the dataset kept for validation\n",
    "data_loader = CIFAR100DataLoader(batch_size=BATCH_SIZE, validation_split=0.1, download=True, num_workers=4, pin_memory=True)\n",
    "trainloader, validloader, testloader = data_loader.train_loader, data_loader.val_loader, data_loader.test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossover probability tuning\n",
    "Fixing Nc=10, J=4 and number of generations/rounds=500, we evaluated different values of crossover probabilities to pick the best one for the final configuration of the EA algorithm. In particular, we tried the following values: 0.2,0.3,0.5 and 0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = [0.05,0.1,0.15,0.2]\n",
    "\n",
    "max_val_acc = 0\n",
    "max_test_acc = 0\n",
    "best_probability = 0\n",
    "\n",
    "for probability in probabilities:\n",
    "  print('Starting test with probability: '+ str(probability))\n",
    "  global_model = LeNet5()\n",
    "  global_model,val_accuracies,val_losses,train_accuracies,train_losses,client_selection_count=EA_algorithm(500,5,2,10,probability,trainloader,validloader,0.1,0.001)\n",
    "  max_validation_accuracy = max(val_accuracies)\n",
    "  print('Max validation accuracy: '+ str(max_validation_accuracy))\n",
    "  if(max_validation_accuracy > max_val_acc):\n",
    "    max_val_acc = max_validation_accuracy\n",
    "  test_accuracy = test(global_model,testloader)\n",
    "  print(\"Test accuracy: \",test_accuracy)\n",
    "  if(test_accuracy > max_test_acc):\n",
    "    max_test_acc = test_accuracy\n",
    "    best_proability = probability\n",
    "\n",
    "print('Best probability found out of the test: '+ str(best_probability)+ ', with a test accuracy of: '+ str(max_test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on non-iid distributions\n",
    "Taking into account the same tests we have performed on the baseline to make a comparison, we will experiment with different non-iid distributions, with Nc=1,5,10,50. Hyperparameter tuning conducted in the same way as the previous experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters tuning function\n",
    "def hyperparameters_tuning(num_classes, rounds):\n",
    "    print(f\"Hyperparameter tuning for num_classes={num_classes}\")\n",
    "    lr_values = [0.1,0.05,0.01,0.005,0.001,0.0005,0.0001]\n",
    "    wd_values = [0.001,0.0001]\n",
    "    best_val_accuracy = 0\n",
    "    best_setting = None\n",
    "    for lr in lr_values:\n",
    "        for wd in wd_values:\n",
    "            print(f\"Learning rate: {lr}, Weight decay: {wd}\")\n",
    "            model = LeNet5()\n",
    "            #using the best values of population_size, num_clients and crossover_probability found in the previous step\n",
    "            _,val_accuracies,val_losses,train_accuracies,train_losses,_=EA_algorithm(rounds,8,4,num_classes,0.5,trainloader,validloader,lr,wd)\n",
    "            plot_metrics(train_accuracies, train_losses,val_accuracies, val_losses, f\"Personal_contribution_tuning{num_classes}_lr_{lr}_wd_{wd}.png\")\n",
    "            max_val_accuracy = max(val_accuracies)\n",
    "            print(f\"Validation accuracy: {max_val_accuracy} with lr: {lr} and wd: {wd}\")\n",
    "            avg_val_accuracy = sum(val_accuracies) / len(val_accuracies)\n",
    "            if avg_val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = avg_val_accuracy\n",
    "                best_setting = (lr, wd)\n",
    "    print(f\"Best setting: {best_setting} with validation accuracy: {best_val_accuracy}\")\n",
    "    return best_setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = [1,5,10,50]\n",
    "\n",
    "# Function to perform the training and testing for a given configuration\n",
    "def run_experiment(num_classes, plot_suffix):\n",
    "    print(f\"Running experiment: num_classes={num_classes}\")\n",
    "    global_model = LeNet5()\n",
    "    #100 rounds for hyperparameter tuning\n",
    "    best_lr, best_wd = hyperparameters_tuning(num_classes = num_classes, rounds=100)\n",
    "\n",
    "    global_model,val_accuracies,val_losses,train_accuracies,train_losses,client_selection_count=EA_algorithm(GLOBAL_ROUNDS,8,4,num_classes,0.5,trainloader,validloader,best_lr,best_wd)\n",
    "    # Testing and plotting\n",
    "    test_accuracy = test(global_model, testloader)\n",
    "    plot_metrics(train_accuracies, train_losses, val_accuracies, val_losses, f\"Contribution_{plot_suffix}_LR_{best_lr}_WD_{best_wd}.png\")\n",
    "    print(f\"Test accuracy for num_classes={num_classes}: {test_accuracy}\")\n",
    "    plot_client_selection(client_selection_count, f\"Client_selection_{plot_suffix}_LR_{best_lr}_WD_{best_wd}.png\")\n",
    "    # Save data for future analysis\n",
    "    save_data(global_model, val_accuracies, val_losses, train_accuracies, train_losses, client_selection_count, f\"Contribution_{plot_suffix}_LR_{best_lr}_WD_{best_wd}.pth\")\n",
    "\n",
    "# Main experiment loop\n",
    "for num_classes in num_classes:  \n",
    "    plot_suffix = f\"num_classes_{num_classes}\"\n",
    "    run_experiment(num_classes, plot_suffix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
